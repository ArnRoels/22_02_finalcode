{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===========================================================\n",
    "Analysis of growth curves of CRISPRi library\n",
    "===========================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy import integrate\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===========================================================\n",
    "functions\n",
    "===========================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all functions\n",
    "\n",
    "def remove_samples(df, samples_to_remove):\n",
    "    return df[~df['Sample'].isin(samples_to_remove)]\n",
    "\n",
    "def convert_time_to_minutes(time_str):\n",
    "        try:\n",
    "            if 'min' in time_str:\n",
    "                hours, minutes = time_str.split(' h ')\n",
    "                minutes = int(minutes.split(' min')[0])\n",
    "            else:\n",
    "                hours = time_str.split(' h')[0]\n",
    "                minutes = 0\n",
    "            hours = int(hours)\n",
    "            total_minutes = hours * 1 + minutes/60\n",
    "            return total_minutes\n",
    "        except ValueError:\n",
    "            return pd.NA  # Return NaN if the time string is not in the expected format\n",
    "        \n",
    "def apply_savgol_filter(group, window_size, polyorder=1):\n",
    "    \"\"\"\n",
    "    Apply Savitzky-Golay filter to smooth the 'OD' values in each group.\n",
    "    \n",
    "    Parameters:\n",
    "        group (DataFrame): Grouped data by 'Sample'.\n",
    "        window_size (int): The length of the filter window. Must be a positive odd integer.\n",
    "        polyorder (int): The order of the polynomial used to fit the samples. Must be less than window_size.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: The original group with an additional 'Smoothed_OD' column.\n",
    "    \"\"\"\n",
    "    # Apply Savitzky-Golay filter to the 'OD' column\n",
    "    group['Smoothed_OD'] = savgol_filter(group['OD'], window_size, polyorder, mode='nearest')\n",
    "    return group\n",
    "\n",
    "\n",
    "def calculate_log2(group):\n",
    "    \"\"\"\n",
    "    Calculate the log2 of 'Smoothed_OD_Blank_Sub' for a given group of rows.\n",
    "    \n",
    "    Parameters:\n",
    "        group (DataFrame): A subset of the DataFrame corresponding to a specific 'Sample' group.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: The original group with an additional 'Log2' column.\n",
    "    \"\"\"\n",
    "    group['Log2'] = np.log2(group['Smoothed_OD_Blank_Sub'])\n",
    "    return group\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def extract_metrics(group):\n",
    "    t = group['Time'].values\n",
    "    y = group['Smoothed_OD_Blank_Sub'].values  # already smoothed\n",
    "\n",
    "    # --- Basic growth metrics ---\n",
    "    auc = np.trapz(y, t)\n",
    "\n",
    "    max_od_idx = np.argmax(y)\n",
    "    max_od = y[max_od_idx]\n",
    "    max_od_time = t[max_od_idx]\n",
    "    last_od = y[-1]\n",
    "\n",
    "    dy_dt = np.gradient(y, t)\n",
    "    max_slope = np.max(dy_dt)\n",
    "\n",
    "    decline_region = dy_dt[max_od_idx:]\n",
    "    decline_rate = np.mean(decline_region) if len(decline_region) > 0 else 0\n",
    "\n",
    "    # --- Peaks with all properties explicitly computed ---\n",
    "    peaks_idx, peak_props = find_peaks(\n",
    "        y,\n",
    "        distance=5,\n",
    "        height=(None, None),        # ✅ ensures 'peak_heights' is returned\n",
    "        prominence=(None, None),    # ensures prominences and bases are computed\n",
    "        width=(None, None),         # ensures width metrics are computed\n",
    "        threshold=None,\n",
    "        plateau_size=None\n",
    "    )\n",
    "    num_peaks = len(peaks_idx)\n",
    "\n",
    "    # Compute widths (needed for width-based metrics)\n",
    "    widths_res = peak_widths(y, peaks_idx, rel_height=0.5)\n",
    "\n",
    "    # --- Helper function to compute max and mean safely ---\n",
    "    def max_mean(arr):\n",
    "        if arr is None or len(arr) == 0:\n",
    "            return np.nan, np.nan\n",
    "        return np.nanmax(arr), np.nanmean(arr)\n",
    "\n",
    "    var_dODdt = np.var(dy_dt)\n",
    "\n",
    "    # --- AUCs over specific time ranges ---\n",
    "    x, y_time = 0, 10\n",
    "    z, w = 10, 14\n",
    "\n",
    "    group1 = group[(group['Time'] >= x) & (group['Time'] <= y_time)]\n",
    "    group2 = group[(group['Time'] >= z) & (group['Time'] <= w)]\n",
    "\n",
    "    auc1 = np.trapz(group1['Smoothed_OD_Blank_Sub'], group1['Time'])\n",
    "    auc2 = np.trapz(group2['Smoothed_OD_Blank_Sub'], group2['Time'])\n",
    "\n",
    "    # --- Peak property summaries (max + mean) ---\n",
    "    peak_height_max, peak_height_mean = max_mean(peak_props.get('peak_heights', []))\n",
    "    peak_prom_max, peak_prom_mean = max_mean(peak_props.get('prominences', []))\n",
    "    peak_left_base_max, peak_left_base_mean = max_mean(peak_props.get('left_bases', []))\n",
    "    peak_right_base_max, peak_right_base_mean = max_mean(peak_props.get('right_bases', []))\n",
    "    peak_width_max, peak_width_mean = max_mean(widths_res[0])\n",
    "    peak_width_height_max, peak_width_height_mean = max_mean(widths_res[1])\n",
    "    peak_left_ip_max, peak_left_ip_mean = max_mean(widths_res[2])\n",
    "    peak_right_ip_max, peak_right_ip_mean = max_mean(widths_res[3])\n",
    "\n",
    "    # --- Collect all results ---\n",
    "    result = {\n",
    "        'AUC': auc,\n",
    "        'AUC1': auc1,\n",
    "        'AUC2': auc2,\n",
    "        'Max_OD': max_od,\n",
    "        'Max_OD_Time (h)': max_od_time,  # convert minutes to hours\n",
    "        'Final_OD': last_od,\n",
    "        'Max_Slope': max_slope,\n",
    "        'Decline_Rate': decline_rate,\n",
    "        'Num_Peaks': num_peaks,\n",
    "        'Var_dODdt': var_dODdt,\n",
    "        'Peak_Height_Max': peak_height_max,\n",
    "        'Peak_Height_Mean': peak_height_mean,\n",
    "        'Peak_Prominence_Max': peak_prom_max,\n",
    "        'Peak_Prominence_Mean': peak_prom_mean,\n",
    "        'Peak_Left_Base_Max': peak_left_base_max,\n",
    "        'Peak_Left_Base_Mean': peak_left_base_mean,\n",
    "        'Peak_Right_Base_Max': peak_right_base_max,\n",
    "        'Peak_Right_Base_Mean': peak_right_base_mean,\n",
    "        'Peak_Width_Max': peak_width_max,\n",
    "        'Peak_Width_Mean': peak_width_mean,\n",
    "        'Peak_Width_Height_Max': peak_width_height_max,\n",
    "        'Peak_Width_Height_Mean': peak_width_height_mean,\n",
    "        'Peak_Left_IP_Max': peak_left_ip_max,\n",
    "        'Peak_Left_IP_Mean': peak_left_ip_mean,\n",
    "        'Peak_Right_IP_Max': peak_right_ip_max,\n",
    "        'Peak_Right_IP_Mean': peak_right_ip_mean\n",
    "    }\n",
    "\n",
    "    return pd.Series(result)\n",
    "\n",
    "\n",
    "def calculate_sliding_regressions(df, window_regression):\n",
    "    \"\"\"\n",
    "    Calculate linear regressions of Log2 values according to time for each 'Sample' over sliding windows of a specified size.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame containing 'Sample', 'Time', and 'Log2' columns.\n",
    "        window_regression (int): The size of the sliding window for the regression.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the regression results for each sliding window.\n",
    "    \"\"\"\n",
    "    regression_results = []\n",
    "\n",
    "    for sample, sample_df in df.groupby('Sample'):\n",
    "        for i in range(len(sample_df) - window_regression + 1):\n",
    "            window_df = sample_df.iloc[i:i+window_regression]\n",
    "            x = window_df['Time'].values\n",
    "            y = window_df['Log2'].values\n",
    "\n",
    "            # Calculate linear regression using np.polyfit\n",
    "            slope, intercept = np.polyfit(x, y, 1)\n",
    "\n",
    "            # Calculate residuals and average residuals\n",
    "            y_fit = slope * x + intercept\n",
    "            residuals = y - y_fit\n",
    "            avg_residuals = np.mean(np.abs(residuals))\n",
    "\n",
    "            # Calculate R-squared\n",
    "            ss_res = np.sum((y - y_fit) ** 2)\n",
    "            ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "            r_squared = 1 - (ss_res / ss_tot)\n",
    "\n",
    "            regression_results.append({\n",
    "                'Sample': sample,\n",
    "                'Start_Time': window_df['Time'].iloc[0],\n",
    "                'End_Time': window_df['Time'].iloc[-1],\n",
    "                'Start_Log2': window_df['Log2'].iloc[0],\n",
    "                'End_Log2': window_df['Log2'].iloc[-1],\n",
    "                'Slope': slope,\n",
    "                'Intercept': intercept,\n",
    "                'Avg_Residuals': avg_residuals,\n",
    "                'R_squared': r_squared\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(regression_results)\n",
    "\n",
    "def plot_sample_regressions(df_back, df_reg, sample_to_plot, plot_name):\n",
    "    # Filter data for the specific sample\n",
    "    sample_data = df_back[df_back['Sample'] == sample_to_plot]\n",
    "    sample_regressions = df_reg[df_reg['Sample'] == sample_to_plot]\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot the Log2 values\n",
    "    plt.scatter(sample_data['Time'], sample_data['Log2'], facecolors='none', edgecolors='lightgrey', s=30, label='Log2 Values')\n",
    "\n",
    "    # Create a color map\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"\", [\"grey\", \"red\"])\n",
    "\n",
    "    # Get the range of slopes\n",
    "    min_slope, max_slope = sample_regressions['Slope'].min(), sample_regressions['Slope'].max()\n",
    "\n",
    "    # Plot each regression line with color based on slope\n",
    "    for _, row in sample_regressions.iterrows():\n",
    "        start_time, end_time = row['Start_Time'], row['End_Time']\n",
    "        slope, intercept = row['Slope'], row['Intercept']\n",
    "        \n",
    "        # Normalize the slope to get a value between 0 and 1 (if multiple slopes)\n",
    "        if min_slope == max_slope:\n",
    "            # Use red color for the slope\n",
    "            norm_slope = slope  # or you could set it to a specific value like 1 or 0\n",
    "            color = 'red'\n",
    "        else:\n",
    "            norm_slope = (slope - min_slope) / (max_slope - min_slope)\n",
    "            color = cmap(norm_slope)\n",
    "           \n",
    "        x = [start_time, end_time]\n",
    "        y = [intercept + slope * start_time, intercept + slope * end_time]\n",
    "        plt.plot(x, y, color=color, alpha=0.7, linewidth=2)\n",
    "\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Log2 of OD600nm')\n",
    "    plt.title(f\"{plot_name} {sample_to_plot}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_two_regressions(title_detail, df_log2, reg1_df, reg2_df, sample_to_plot):\n",
    "    sample_data = df_log2[df_log2['Sample'] == sample_to_plot]\n",
    "    reg1 = reg1_df[reg1_df['Sample'] == sample_to_plot]\n",
    "    reg2 = reg2_df[reg2_df['Sample'] == sample_to_plot]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(sample_data['Time'], sample_data['Log2'], facecolors='none', edgecolors='lightgrey', s=30, label='Log2 Values')\n",
    "\n",
    "    # First exponential phase regression (black)\n",
    "    if not reg1.empty:\n",
    "        x1 = [reg1['Start_Time'].values[0], reg1['End_Time'].values[0]]\n",
    "        y1 = [reg1['Intercept'].values[0] + reg1['Slope'].values[0] * x1[0],\n",
    "              reg1['Intercept'].values[0] + reg1['Slope'].values[0] * x1[1]]\n",
    "        plt.plot(x1, y1, color='black', linewidth=2, label='First Exponential Phase')\n",
    "\n",
    "    # Secondary exponential phase regression (red)\n",
    "    if not reg2.empty:\n",
    "        x2 = [reg2['Start_Time'].values[0], reg2['End_Time'].values[0]]\n",
    "        y2 = [reg2['Intercept'].values[0] + reg2['Slope'].values[0] * x2[0],\n",
    "              reg2['Intercept'].values[0] + reg2['Slope'].values[0] * x2[1]]\n",
    "        plt.plot(x2, y2, color='red', linewidth=2, label='Secondary Exponential Phase')\n",
    "\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Log2 of OD600nm')\n",
    "    plt.title(f'Best regressions {title_detail} for {sample_to_plot}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def refine_exponential_phase(top_rows_df, df_log2, thresh):\n",
    "    refined_df = top_rows_df.copy()\n",
    "\n",
    "    for idx, row in refined_df.iterrows():\n",
    "        sample = row['Sample']\n",
    "        residues_thresh = row['Avg_Residuals'] * thresh \n",
    "\n",
    "        sample_data = df_log2[df_log2['Sample'] == sample]\n",
    "        current_start, current_end = row['Start_Time'], row['End_Time']\n",
    "\n",
    "        # Expand window towards lower time values\n",
    "        current_start = expand_window(sample_data, current_start, current_end, residues_thresh, direction='backward')\n",
    "\n",
    "        # Expand window towards higher time values\n",
    "        current_end = expand_window(sample_data, current_start, current_end, residues_thresh, direction='forward')\n",
    "\n",
    "        # Update the refined dataframe\n",
    "        refined_df.at[idx, 'Start_Time'] = current_start\n",
    "        refined_df.at[idx, 'End_Time'] = current_end\n",
    "        refined_df.at[idx, 'Start_Log2'] = get_log2_value(sample_data, current_start)\n",
    "        refined_df.at[idx, 'End_Log2'] = get_log2_value(sample_data, current_end)\n",
    "        refined_df.at[idx, 'Avg_Residuals'], refined_df.at[idx, 'Slope'], refined_df.at[idx, 'Intercept'] = calculate_regression_data(sample_data, current_start, current_end)\n",
    "\n",
    "    return refined_df\n",
    "\n",
    "def expand_window(data, current_start, current_end, threshold, direction):\n",
    "    while True:\n",
    "        if direction == 'backward':\n",
    "            new_time = get_previous_time(data, current_start)\n",
    "            if new_time is None or exceeds_threshold(data, new_time, current_end, threshold):\n",
    "                break\n",
    "            current_start = new_time\n",
    "        elif direction == 'forward':\n",
    "            new_time = get_next_time(data, current_end)\n",
    "            if new_time is None or exceeds_threshold(data, current_start, new_time, threshold):\n",
    "                break\n",
    "            current_end = new_time\n",
    "    return current_start if direction == 'backward' else current_end\n",
    "\n",
    "def exceeds_threshold(data, start_time, end_time, threshold):\n",
    "    return calculate_regression_data(data, start_time, end_time)[0] > threshold\n",
    "\n",
    "\n",
    "def calculate_regression_data(data, start_time, end_time):\n",
    "    window = data[(data['Time'] >= start_time) & (data['Time'] <= end_time)]\n",
    "    slope, intercept, _, _, _ = stats.linregress(window['Time'], window['Log2'])\n",
    "    residuals = window['Log2'] - (slope * window['Time'] + intercept)\n",
    "    avg_residuals = np.mean(np.abs(residuals))\n",
    "    return avg_residuals, slope, intercept\n",
    "\n",
    "\n",
    "def get_log2_value(data, time):\n",
    "    return data.loc[data['Time'] == time, 'Log2'].values[0]\n",
    "\n",
    "def get_previous_time(data, current_time):\n",
    "    previous_times = data[data['Time'] < current_time]['Time']\n",
    "    return previous_times.max() if not previous_times.empty else None\n",
    "\n",
    "def get_next_time(data, current_time):\n",
    "    next_times = data[data['Time'] > current_time]['Time']\n",
    "    return next_times.min() if not next_times.empty else None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===========================================================\n",
    "import data\n",
    "===========================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# -------------------------------\n",
    "# Define variables\n",
    "# -------------------------------\n",
    "sheet_name = 'Table All Cycles'\n",
    "skiprows = 12\n",
    "nrows = 170\n",
    "time_format = 'XX h XX min'\n",
    "\n",
    "# -------------------------------\n",
    "# Define replicate files\n",
    "# -------------------------------\n",
    "files = [\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/crispri/plate1_rep1.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/crispri/plate1_rep2.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/crispri/plate1_rep3.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/xylose/plate1_xylose_rep1.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/xylose/plate1_xylose_rep2.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/xylose/plate1_xylose_rep3.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/crispri/plate2_rep1.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/crispri/plate2_rep2.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/crispri/plate2_rep3.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/xylose/plate2_xylose_rep1.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/xylose/plate2_xylose_rep2.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/xylose/plate2_xylose_rep3.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/crispri/plate3_rep1.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/crispri/plate3_rep2.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/crispri/plate3_rep3.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/xylose/plate3_xylose_rep1.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/xylose/plate3_xylose_rep2.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/xylose/plate3_xylose_rep3.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/crispri/plate4_rep1.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/crispri/plate4_rep2.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/crispri/plate4_rep3.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/xylose/plate4_xylose_rep1.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/xylose/plate4_xylose_rep2.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/xylose/plate4_xylose_rep3.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/251009_missingreps.xlsx\",\n",
    "    \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/Plate2_Rep4_andMissingrep.xlsx\",\n",
    "     \"C:/Users/arnou/Documents/thesis/Resultaten/voorpythoncode/23_10_25Plate7missingreps.xlsx\"\n",
    "]\n",
    "\n",
    "# -------------------------------\n",
    "# Load metadata Excel with multiple sheets\n",
    "# -------------------------------\n",
    "file_path_meta = 'C:/Users/arnou/Documents/thesis/Resultaten/MetaData/MetaDataNew13.xlsx'  # full path including .xlsx\n",
    "metadata_excel = pd.ExcelFile(file_path_meta)\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for i, file_path in enumerate(files):\n",
    "    # -------------------------------\n",
    "    # Load each replicate\n",
    "    # -------------------------------\n",
    "    df_rep = pd.read_excel(\n",
    "        file_path,\n",
    "        sheet_name=sheet_name,\n",
    "        header=[0, 1],\n",
    "        index_col=None,\n",
    "        skiprows=skiprows,\n",
    "        nrows=nrows\n",
    "    )\n",
    "\n",
    "    # Flatten headers\n",
    "    df_rep.columns = [col[0] for col in df_rep.columns]\n",
    "    df_rep.columns.values[1] = \"Time\"\n",
    "    df_rep = df_rep[df_rep.columns[1:]]\n",
    "\n",
    "    # Melt to long format\n",
    "    df_melted = pd.melt(df_rep, id_vars='Time', var_name='Sample', value_name='OD')\n",
    "\n",
    "    \n",
    "    df_melted[\"source_file\"] = file_path\n",
    "\n",
    "    # -------------------------------\n",
    "    # Merge with corresponding metadata sheet\n",
    "    # -------------------------------\n",
    "    # Select the correct sheet (sheet1 → first file, sheet2 → second file, etc.)\n",
    "    sheet_name_meta = metadata_excel.sheet_names[i]  # i-th sheet corresponds to i-th file\n",
    "    df_meta = pd.read_excel(file_path_meta, sheet_name=sheet_name_meta, header=0, index_col=None)\n",
    "\n",
    "    df_merged = df_melted.merge(\n",
    "        df_meta,\n",
    "        left_on=\"Sample\",\n",
    "        right_on=\"MetaData_Well\",\n",
    "        how=\"left\"\n",
    "    ).rename(columns={\n",
    "        \"Sample\": \"Well\",\n",
    "        \"MetaData_gene\": \"Sample\"\n",
    "    })\n",
    "\n",
    "    dfs.append(df_merged)\n",
    "\n",
    "# -------------------------------\n",
    "# Combine all replicates\n",
    "# -------------------------------\n",
    "df_final = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# -------------------------------\n",
    "# Reformat time\n",
    "# -------------------------------\n",
    "if time_format == 'XX h XX min':\n",
    "    df_final['Time'] = df_final['Time'].apply(convert_time_to_minutes)\n",
    "elif time_format == 'decimal hour':\n",
    "    df_final['Time'] = df_final['Time'] * 60\n",
    "elif time_format == 'minutes':\n",
    "    df_final = df_final.rename(columns={'Time': 'Time'})\n",
    "else:\n",
    "    print('Unknown time format.')\n",
    "\n",
    "print(\"Final merged and reformatted data:\")\n",
    "print(df_final)\n",
    "df_melted = df_final\n",
    "print(df_melted)\n",
    "\n",
    "# -------------------------------\n",
    "# Select which plate(s) to analyze\n",
    "# -------------------------------\n",
    "# Options:\n",
    "#   'all' → all plates together\n",
    "#   ['Plaat_1'] → just plate 1\n",
    "#   ['Plaat_1', 'Plaat_2'] → a combination of plates\n",
    "plates_to_analyze = ['all']  # change this as needed\n",
    "\n",
    "if plates_to_analyze != ['all']:\n",
    "    df_filtered = df_final[df_final['MetaData_Plaat'].isin(plates_to_analyze)].copy()\n",
    "else:\n",
    "    df_filtered = df_final.copy()\n",
    "\n",
    "print(f\"Data selected for plates: {plates_to_analyze}\")\n",
    "print(df_filtered)\n",
    "\n",
    "df_melted = df_filtered\n",
    "print(df_melted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Step 1: Get unique samples alphabetically ---\n",
    "samples = df_melted['Sample'].unique()  \n",
    "n_rows = (len(samples) + 2) // 3  # Calculate number of rows for subplots\n",
    "\n",
    "# --- Step 2: Create figure and subplots ---\n",
    "fig, axes = plt.subplots(n_rows, 3, figsize=(15, 5 * n_rows))\n",
    "axes = axes.flatten()\n",
    "print('melted')\n",
    "print(df_melted)\n",
    "# --- Step 3: Plot each sample ---\n",
    "for i, sample in enumerate(samples):\n",
    "    sample_data = df_melted[df_melted['Sample'] == sample]\n",
    "    print('sample data')\n",
    "    print(sample_data)\n",
    "\n",
    "    # Plot each replicate in a different color\n",
    "    for (rep,xylose), rep_data in sample_data.groupby(['rep','Xylose']):\n",
    "        print(rep_data)\n",
    "        axes[i].plot(rep_data['Time'], rep_data['OD'], label=f'Rep {rep} {xylose}', alpha=0.8)\n",
    "\n",
    "    axes[i].set_title(sample)\n",
    "    axes[i].set_xlabel('Time (min)')\n",
    "    axes[i].set_ylabel('OD')\n",
    "    axes[i].legend()\n",
    "\n",
    "# --- Step 4: Remove any unused subplots ---\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: print sample names alphabetically\n",
    "print('List of sample names (alphabetical):')\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for analysis\n",
    "\n",
    "# List of specific sample–replicate combinations to exclude\n",
    "# Format: ('Sample name', replicate_number)\n",
    "# Example: [('Strain name:  CAG74399_1; Gene target: no_sgRNA', 2), ('Strain name:  BEC00920; Gene target: gltX', 1)]\n",
    "\n",
    "\n",
    "samples_to_remove = [\n",
    "    ('Strain name:  BEC14530; Gene target: rnjA', 1, 'no xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC14530; Gene target: rnjA', 2, 'no xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC14530; Gene target: rnjA', 3, 'no xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC25290; Gene target: era', 1, 'no xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC25290; Gene target: era', 2, 'no xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC25290; Gene target: era', 3, 'no xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC01500; Gene target: rpsI', 1, 'no xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC01500; Gene target: rpsI', 2, 'no xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC01500; Gene target: rpsI', 3, 'no xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC16750; Gene target: asd', 1, 'no xylose', 'Plaat_4'),\n",
    "    ('Strain name:  BEC16750; Gene target: asd', 2, 'no xylose', 'Plaat_4'),\n",
    "    ('Strain name:  BEC16750; Gene target: asd', 3, 'no xylose', 'Plaat_4'),\n",
    "    ('Strain name:  BEC14530; Gene target: rnjA', 1, 'xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC14530; Gene target: rnjA', 2, 'xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC14530; Gene target: rnjA', 3, 'xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC25290; Gene target: era', 1, 'xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC25290; Gene target: era', 2, 'xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC25290; Gene target: era', 3, 'xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC01500; Gene target: rpsI', 1, 'xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC01500; Gene target: rpsI', 2, 'xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC01500; Gene target: rpsI', 3, 'xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC16750; Gene target: asd', 1, 'xylose', 'Plaat_4'),\n",
    "    ('Strain name:  BEC16750; Gene target: asd', 2, 'xylose', 'Plaat_4'),\n",
    "    ('Strain name:  BEC16750; Gene target: asd', 3, 'xylose', 'Plaat_4'),\n",
    "    ('Strain name:  BEC17370; Gene target: nrdI', 1, 'xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC17370; Gene target: nrdI', 2, 'xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC17370; Gene target: nrdI', 3, 'xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC00920; Gene target: gltX', 1, 'xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC00920; Gene target: gltX', 2, 'xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC00920; Gene target: gltX', 3, 'xylose', 'Plaat_1'),\n",
    "    ('Strain name:  BEC35740; Gene target: tagD', 1, 'xylose', 'Plaat_3'),\n",
    "    ('Strain name:  BEC35740; Gene target: tagD', 2, 'xylose', 'Plaat_3'),\n",
    "    ('Strain name:  BEC35740; Gene target: tagD', 3, 'xylose', 'Plaat_3'),\n",
    "    ('Strain name:  CAG74399_15; Gene target: rpsN', 2, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC15890; Gene target: plsX', 3, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC18100; Gene target: parC', 1, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC22840; Gene target: engA', 2, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC28850; Gene target: rplT', 2, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC15180; Gene target: murE', 3, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC13300; Gene target: mgtE', 2, 'no xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC13300; Gene target: mgtE', 3, 'no xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC06070; Gene target: ydiP', 1, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC22780; Gene target: folE', 2, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC21810; Gene target: dfrA', 3, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC01040; Gene target: rplJ', 2, 'xylose', 'Plaat_3'),\n",
    "('Strain name:  BEC01080; Gene target: rpoC', 2, 'xylose', 'Plaat_3'),\n",
    "('Strain name:  BEC15220; Gene target: murG', 2, 'xylose', 'Plaat_3'),\n",
    "('Strain name:  BEC16040; Gene target: rplS', 2, 'xylose', 'Plaat_3'),\n",
    "('Strain name:  BEC16580; Gene target: polC', 1, 'no xylose', 'Plaat_3'),\n",
    "('Strain name:  BEC17910; Gene target: yneF', 2, 'xylose', 'Plaat_3'),\n",
    "('Strain name:  BEC01360; Gene target: secY', 2, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  BEC01430; Gene target: rpoA', 3, 'no xylose', 'Plaat_4'),\n",
    "('Strain name:  BEC15290.226; Gene target: ftsZ226', 2, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  BEC15230; Gene target: murB', 3, 'no xylose', 'Plaat_4'),\n",
    "('Strain name:  BEC15940; Gene target: smc', 2, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  BEC15990; Gene target: rpsP', 3, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  BEC24310; Gene target: folD', 3, 'no xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_89; Gene target: no_sgRNA', 1, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_12; Gene target: no_sgRNA', 1, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  CAG74399_12; Gene target: no_sgRNA', 2, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  CAG74399_12; Gene target: no_sgRNA', 3, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  CAG74399_12; Gene target: no_sgRNA', 1, 'no xylose', 'Plaat_2'),\n",
    "('Strain name:  CAG74399_12; Gene target: no_sgRNA', 2, 'no xylose', 'Plaat_2'),\n",
    "('Strain name:  CAG74399_12; Gene target: no_sgRNA', 3, 'no xylose', 'Plaat_2'),\n",
    "('Strain name:  CAG74399_39; Gene target: no_sgRNA', 1, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_56; Gene target: no_sgRNA', 3, 'no xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_59; Gene target: no_sgRNA', 3, 'no xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_62; Gene target: no_sgRNA', 1, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  CAG74399_62; Gene target: no_sgRNA', 2, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  CAG74399_62; Gene target: no_sgRNA', 3, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  CAG74399_62; Gene target: no_sgRNA', 1, 'no xylose', 'Plaat_2'),\n",
    "('Strain name:  CAG74399_62; Gene target: no_sgRNA', 2, 'no xylose', 'Plaat_2'),\n",
    "('Strain name:  CAG74399_62; Gene target: no_sgRNA', 3, 'no xylose', 'Plaat_2'),\n",
    "('Strain name:  CAG74399_75; Gene target: no_sgRNA', 3, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_75; Gene target: no_sgRNA', 2, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_75; Gene target: no_sgRNA', 1, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_77; Gene target: no_sgRNA', 1, 'no xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_83; Gene target: no_sgRNA', 1, 'no xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_84; Gene target: no_sgRNA', 3, 'no xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_86; Gene target: no_sgRNA', 1, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_86; Gene target: no_sgRNA', 2, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_86; Gene target: no_sgRNA', 3, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_86; Gene target: no_sgRNA', 1, 'no xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_86; Gene target: no_sgRNA', 2, 'no xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_86; Gene target: no_sgRNA', 3, 'no xylose', 'Plaat_4'),\n",
    "('Strain name:  BEC16550; Gene target: dxr', 1, 'no xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC16550; Gene target: dxr', 2, 'no xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC16550; Gene target: dxr', 3, 'no xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC28850; Gene target: rplT', 1, 'no xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC28850; Gene target: rplT', 2, 'no xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC28850; Gene target: rplT', 3, 'no xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC28870; Gene target: infC', 1, 'no xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC28870; Gene target: infC', 2, 'no xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC28870; Gene target: infC', 3, 'no xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC01500; Gene target: rpsI', 1, 'no xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC01500; Gene target: rpsI', 2, 'no xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC01500; Gene target: rpsI', 3, 'no xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC14530; Gene target: rnjA', 1, 'no xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC14530; Gene target: rnjA', 2, 'no xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC14530; Gene target: rnjA', 3, 'no xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC31650; Gene target: mrpF', 1, 'no xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC31650; Gene target: mrpF', 2, 'no xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC31650; Gene target: mrpF', 3, 'no xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC32670; Gene target: sufB', 1, 'no xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC32670; Gene target: sufB', 2, 'no xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC32670; Gene target: sufB', 3, 'no xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC01320.2; Gene target: rplR-2', 1, 'no xylose', 'Plaat_3'),\n",
    "('Strain name:  BEC01320.2; Gene target: rplR-2', 2, 'no xylose', 'Plaat_3'),\n",
    "('Strain name:  BEC01320.2; Gene target: rplR-2', 3, 'no xylose', 'Plaat_3'),\n",
    "('Strain name:  BEC01340; Gene target: rpmD', 1, 'no xylose', 'Plaat_3'),\n",
    "('Strain name:  BEC01340; Gene target: rpmD', 2, 'no xylose', 'Plaat_3'),\n",
    "('Strain name:  BEC01340; Gene target: rpmD', 3, 'no xylose', 'Plaat_3'),\n",
    "('Strain name:  BEC17380; Gene target: nrdE', 1, 'no xylose', 'Plaat_3'),\n",
    "('Strain name:  BEC17380; Gene target: nrdE', 2, 'no xylose', 'Plaat_3'),\n",
    "('Strain name:  BEC17380; Gene target: nrdE', 3, 'no xylose', 'Plaat_3'),\n",
    "('Strain name:  BEC25200; Gene target: sigA', 1, 'no xylose', 'Plaat_4'),\n",
    "('Strain name:  BEC25200; Gene target: sigA', 2, 'no xylose', 'Plaat_4'),\n",
    "('Strain name:  BEC25200; Gene target: sigA', 3, 'no xylose', 'Plaat_4'),\n",
    "('Strain name:  BEC01770; Gene target: glmM', 1, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC01770; Gene target: glmM', 2, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC01770; Gene target: glmM', 3, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC15910; Gene target: fabG', 1, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC15910; Gene target: fabG', 2, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC15910; Gene target: fabG', 3, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC25270; Gene target: glyQ', 1, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC25270; Gene target: glyQ', 2, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC25270; Gene target: glyQ', 3, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC28870; Gene target: infC', 1, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC28870; Gene target: infC', 2, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC28870; Gene target: infC', 3, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC_TRNA_23; Gene target: trnH', 1, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC_TRNA_23; Gene target: trnH', 2, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC_TRNA_23; Gene target: trnH', 3, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC00460; Gene target: ipk', 1, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC00460; Gene target: ipk', 2, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC00460; Gene target: ipk', 3, 'xylose', 'Plaat_1'),\n",
    "('Strain name:  BEC01500; Gene target: rpsI', 1, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC01500; Gene target: rpsI', 2, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC01500; Gene target: rpsI', 3, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC00380; Gene target: metS', 1, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC00380; Gene target: metS', 2, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC00380; Gene target: metS', 3, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC16530; Gene target: uppS', 1, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC16530; Gene target: uppS', 2, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC16530; Gene target: uppS', 3, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC27560; Gene target: hisS', 1, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC27560; Gene target: hisS', 2, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC27560; Gene target: hisS', 3, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC14190; Gene target: dapL', 1, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC14190; Gene target: dapL', 2, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC14190; Gene target: dapL', 3, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC22420; Gene target: panC', 1, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC22420; Gene target: panC', 2, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC22420; Gene target: panC', 3, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC16920; Gene target: pgsA', 1, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC16920; Gene target: pgsA', 2, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC16920; Gene target: pgsA', 3, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC22490; Gene target: dapB', 1, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC22490; Gene target: dapB', 2, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC22490; Gene target: dapB', 3, 'xylose', 'Plaat_2'),\n",
    "('Strain name:  BEC15930; Gene target: rnc', 1, 'xylose', 'Plaat_3'),\n",
    "('Strain name:  BEC15930; Gene target: rnc', 2, 'xylose', 'Plaat_3'),\n",
    "('Strain name:  BEC15930; Gene target: rnc', 3, 'xylose', 'Plaat_3'),\n",
    "('Strain name:  BEC29660; Gene target: rpsD', 1, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  BEC29660; Gene target: rpsD', 2, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  BEC29660; Gene target: rpsD', 3, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  BEC32110; Gene target: yumC', 1, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  BEC32110; Gene target: yumC', 2, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  BEC32110; Gene target: yumC', 3, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  leeg; Gene target: nothing', 1, 'xylose', 'Plate_fout'),\n",
    "('Strain name:  leeg; Gene target: nothing', 2, 'xylose', 'Plate_fout'),\n",
    "('Strain name:  leeg; Gene target: nothing', 3, 'xylose', 'Plate_fout'),\n",
    "('Strain name:  leeg; Gene target: nothing', 1, 'xylose', 'Plate_fout'),\n",
    "('Strain name:  leeg; Gene target: nothing', 2, 'xylose', 'Plate_fout'),\n",
    "('Strain name:  leeg; Gene target: nothing', 3, 'xylose', 'Plate_fout'),\n",
    "('Strain name:  leeg; Gene target: nothing', 1, 'xylose', 'Plate_fout'),\n",
    "('Strain name:  leeg; Gene target: nothing', 2, 'xylose', 'Plate_fout'),\n",
    "('Strain name:  leeg; Gene target: nothing', 3, 'xylose', 'Plate_fout'),\n",
    "('Strain name:  leeg; Gene target: nothing', 1, 'xylose', 'Plate_fout'),\n",
    "('Strain name:  leeg; Gene target: nothing', 2, 'xylose', 'Plate_fout'),\n",
    "('Strain name:  leeg; Gene target: nothing', 3, 'xylose', 'Plate_fout'),\n",
    "('Strain name:  CAG74399_83; Gene target: no_sgRNA', 1, 'xylose', 'Plaat_3'),\n",
    "('Strain name:  CAG74399_83; Gene target: no_sgRNA', 2, 'xylose', 'Plaat_3'),\n",
    "('Strain name:  CAG74399_83; Gene target: no_sgRNA', 3, 'xylose', 'Plaat_3'),\n",
    "('Strain name:  CAG74399_39; Gene target: no_sgRNA', 2, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_39; Gene target: no_sgRNA', 3, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_57; Gene target: no_sgRNA', 2, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_57; Gene target: no_sgRNA', 1, 'no xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_57; Gene target: no_sgRNA', 2, 'no xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_57; Gene target: no_sgRNA', 3, 'no xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_89; Gene target: no_sgRNA', 2, 'xylose', 'Plaat_4'),\n",
    "('Strain name:  CAG74399_89; Gene target: no_sgRNA', 3, 'xylose', 'Plaat_4'),\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "samples_to_remove_all = [\"Strain name:  SGL999; Gene target: nothing\",\"Strain name:  leeg; Gene target: nothing\",\"Strain name:  xylosevergeten; Gene target: fout\"]\n",
    "\n",
    "\n",
    "# If you want to remove *all* replicates of a sample, you can also list it as just the sample name\n",
    "#samples_to_remove_all = [\n",
    "    # 'Strain name:  BAD_SAMPLE; Gene target: something'\n",
    "\n",
    "\n",
    "# Example of setting diauxic samples (optional)\n",
    "# samples_diauxic = ['Strain name:  ABC123; Gene target: foo']\n",
    "\n",
    "# Example of a sample to plot in detail later\n",
    "sample_to_plot = 'Strain name:  BEC22600; Gene target: aroE'\n",
    "\n",
    "# Parameters\n",
    "window_size = 50          # Smoothing window for Savitzky–Golay filter\n",
    "window_regression = 23   # Window size for best linear regression fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export_path = 'C:/Users/arnou/Documents/thesis/Resultaten/exportfiles/analysisy.xlsx'\n",
    "\n",
    "\n",
    "#df_melted.to_excel(export_path, index=False, float_format='%.12g')\n",
    "#print(f\"File successfully exported to {export_path}\")\n",
    "\n",
    "df_melted = df_melted[\n",
    "    ~df_melted.set_index(['Sample', 'rep', 'Xylose', 'MetaData_Plaat']).index.isin(samples_to_remove)\n",
    "]\n",
    "df_melted = df_melted[\n",
    "    ~df_melted.apply(lambda row: (row[\"Sample\"]) in samples_to_remove_all, axis=1)\n",
    "]\n",
    "\n",
    "#('Strain name:  CAG74399_12; Gene target: no_sgRNA', 2, 'xylose', 'Plaat_2')\n",
    "\n",
    "#export_path = 'C:/Users/arnou/Documents/thesis/Resultaten/exportfiles/analysisyy.xlsx'\n",
    "\n",
    "\n",
    "#df_melted.to_excel(export_path, index=False, float_format='%.12g')\n",
    "#print(f\"File successfully exported to {export_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===========================================================\n",
    "Preprocessing\n",
    "===========================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- Smoothing using the Savitzky-Golay filter ---\n",
    "\n",
    "# Group by both Sample and replicate\n",
    "df_smoothed = df_melted.groupby(['Sample', 'rep','Xylose']).apply(\n",
    "    apply_savgol_filter,\n",
    "    window_size=window_size,\n",
    "    polyorder=1\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(df_smoothed.head())\n",
    "\n",
    "# --- Check-up plot for smoothing step ---\n",
    "\n",
    "if sample_to_plot in df_smoothed['Sample'].unique():\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    for (rep,xylose), rep_data in df_smoothed[df_smoothed['Sample'] == sample_to_plot].groupby(['rep', 'Xylose']):\n",
    "        ax.plot(rep_data['Time'], rep_data['OD'], linestyle='--', marker='o', alpha=0.6, label=f'Raw Rep {rep}{xylose}')\n",
    "        ax.plot(rep_data['Time'], rep_data['Smoothed_OD'], marker='o', label=f'Smoothed Rep {rep}')\n",
    "\n",
    "    ax.set_title(f'OD before and after smoothing for {sample_to_plot}')\n",
    "    ax.set_xlabel('Time (minutes)')\n",
    "    ax.set_ylabel('OD 600nm')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('The specified sample is not present in the smoothed data.')\n",
    "\n",
    "\n",
    "# --- Blank calculation (per sample–replicate) ---\n",
    "\n",
    "filtered_df = df_smoothed[(df_smoothed['Time'] >= 1) & (df_smoothed['Time'] <= 15)]\n",
    "\n",
    "minimum_smoothed_od = (\n",
    "    filtered_df.groupby(['Sample', 'rep','Xylose'])['Smoothed_OD'].min().rename('Blank_value')\n",
    ")\n",
    "\n",
    "df_smoothed = df_smoothed.merge(minimum_smoothed_od, on=['Sample', 'rep','Xylose'], how='left')\n",
    "\n",
    "print(\"Blank values for each sample-replicate:\")\n",
    "print(minimum_smoothed_od)\n",
    "print('-' * 65)\n",
    "\n",
    "# --- Subtract blank values ---\n",
    "\n",
    "df_blank_subs = df_smoothed.copy()\n",
    "df_blank_subs['Smoothed_OD_Blank_Sub'] = df_blank_subs['Smoothed_OD'] - df_blank_subs['Blank_value']\n",
    "\n",
    "negative_values_count = (df_blank_subs['Smoothed_OD_Blank_Sub'] < 0).sum()\n",
    "print(f\"Number of negative, blank-subtracted OD values: {negative_values_count}\")\n",
    "\n",
    "#all smoothed plots\n",
    "# --- Plot curves after smoothing and blank subtraction ---\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get unique samples\n",
    "samples = df_blank_subs['Sample'].unique()\n",
    "n_rows = (len(samples) + 2) // 3  # Calculate number of rows for subplots\n",
    "\n",
    "# Create figure and subplots\n",
    "fig, axes = plt.subplots(n_rows, 3, figsize=(15, 5 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each sample\n",
    "for i, sample in enumerate(samples):\n",
    "    sample_data = df_blank_subs[df_blank_subs['Sample'] == sample]\n",
    "\n",
    "    # Plot each replicate\n",
    "    for (rep,xylose), rep_data in sample_data.groupby(['rep', 'Xylose']):\n",
    "        axes[i].plot(\n",
    "            rep_data['Time'],\n",
    "            rep_data['Smoothed_OD_Blank_Sub'],\n",
    "            label=f'Rep {rep}{xylose}',\n",
    "            alpha=0.8\n",
    "        )\n",
    "\n",
    "    axes[i].set_title(f'{sample}')\n",
    "    axes[i].set_xlabel('Time (hours)')\n",
    "    axes[i].set_ylabel('OD ')\n",
    "    axes[i].legend()\n",
    "    #axes[i].set_xlim([0, 15])\n",
    "    #axes[i].set_ylim([0, y_max])\n",
    "\n",
    "# Remove unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('List of sample names (smoothed + blank-subtracted):')\n",
    "print(list(samples))\n",
    "\n",
    "\n",
    "# --- Check-up plot for blank subtraction ---\n",
    "\n",
    "\n",
    "if sample_to_plot in df_blank_subs['Sample'].unique():\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    for (rep,xylose), rep_data in df_blank_subs[df_blank_subs['Sample'] == sample_to_plot].groupby(['rep', 'Xylose']):\n",
    "        ax.plot(rep_data['Time'], rep_data['Smoothed_OD_Blank_Sub'], marker='o', label=f'Rep {rep}')\n",
    "    ax.set_xlabel('Time (minutes)')\n",
    "    ax.set_ylabel('Blank-subtracted OD')\n",
    "    ax.set_title(f'Blank-subtracted OD for {sample_to_plot}')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('The specified sample is not present in this acquisition.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_strains = df_smoothed['Sample'].nunique()\n",
    "print(f\"Number of different strains (unique Sample values): {num_strains}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_strains = df_smoothed['Sample'].nunique()\n",
    "print(f\"Number of different strains (unique Sample values): {num_strains}\")\n",
    "\n",
    "# --- count no_sgRNA vs others ---\n",
    "sample_list = df_smoothed['Sample'].unique()\n",
    "\n",
    "num_no_sgRNA = sum(\"no_sgRNA\".lower() in s.lower() for s in sample_list)\n",
    "num_with_sgRNA = num_strains - num_no_sgRNA\n",
    "\n",
    "print(f\"Strains with no_sgRNA: {num_no_sgRNA}\")\n",
    "print(f\"Strains with sgRNA (mutants): {num_with_sgRNA}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===========================================================\n",
    "Visualization and verification\n",
    "===========================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot mean growth curves with standard deviation as a shaded area\n",
    "def plot_gene_targets_mean_std(df, gene_targets, time_limit=(0, 14), figsize=(10,6)):\n",
    "    \"\"\"\n",
    "    For each gene target, plot the mean growth curve (line) and standard deviation (shaded area)\n",
    "    for replicates with and without xylose on the same plot.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from matplotlib.lines import Line2D\n",
    "    from matplotlib.patches import Patch\n",
    "    \n",
    "    if not isinstance(gene_targets, (list, tuple)):\n",
    "        gene_targets = [gene_targets]\n",
    "    targets_lower = gene_targets\n",
    "\n",
    "    # Helper function to ensure Xylose_flag column exists\n",
    "    if 'Xylose_flag' not in df.columns:\n",
    "        def _is_xylose_val(v):\n",
    "            try:\n",
    "                s = str(v).strip().lower()\n",
    "                return s in (\"true\", \"yes\", \"1\", \"xylose\", \"y\")\n",
    "            except Exception:\n",
    "                return False\n",
    "        df = df.copy()\n",
    "        df['Xylose_flag'] = df['Xylose'].apply(_is_xylose_val)\n",
    "\n",
    "    # --- FONT SIZE DEFINITIONS (DOUBLED) ---\n",
    "    TITLE_FONT = 24\n",
    "    LABEL_FONT = 20\n",
    "    TICK_FONT = 16\n",
    "    LEGEND_FONT = 16\n",
    "\n",
    "    for target in targets_lower:\n",
    "        mask = df['Sample'].astype(str).str.contains(target)\n",
    "        if mask.sum() == 0:\n",
    "            print(f'No samples match gene target: {target}')\n",
    "            continue\n",
    "            \n",
    "        sel = df[mask].copy()\n",
    "\n",
    "        # Group data by Time and Xylose_flag to calculate mean and std\n",
    "        grouped_data = sel.groupby(['Xylose_flag', 'Time'])['Smoothed_OD'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "        # Separate data for 'With xylose' and 'Without xylose'\n",
    "        data_xylose = grouped_data[grouped_data['Xylose_flag'] == True]\n",
    "        data_no_xylose = grouped_data[grouped_data['Xylose_flag'] == False]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        # --- Plot With Xylose (Blue) ---\n",
    "        if not data_xylose.empty:\n",
    "            time_xylose = data_xylose['Time']\n",
    "            mean_xylose = data_xylose['mean']\n",
    "            std_xylose = data_xylose['std'].fillna(0)\n",
    "            \n",
    "            ax.plot(time_xylose, mean_xylose, color='blue', linewidth=2.5, label='xylose')\n",
    "            ax.fill_between(\n",
    "                time_xylose, \n",
    "                mean_xylose - std_xylose, \n",
    "                mean_xylose + std_xylose, \n",
    "                color='blue', \n",
    "                alpha=0.2, \n",
    "                edgecolor='none'\n",
    "            )\n",
    "\n",
    "        # --- Plot Without Xylose (Green) ---\n",
    "        if not data_no_xylose.empty:\n",
    "            time_no_xylose = data_no_xylose['Time']\n",
    "            mean_no_xylose = data_no_xylose['mean']\n",
    "            std_no_xylose = data_no_xylose['std'].fillna(0)\n",
    "            \n",
    "            ax.plot(time_no_xylose, mean_no_xylose, color='green', linewidth=2.5, label='no xylose')\n",
    "            ax.fill_between(\n",
    "                time_no_xylose, \n",
    "                mean_no_xylose - std_no_xylose, \n",
    "                mean_no_xylose + std_no_xylose, \n",
    "                color='green', \n",
    "                alpha=0.2, \n",
    "                edgecolor='none'\n",
    "            )\n",
    "\n",
    "        # --- APPLY DOUBLED FONT SIZES ---\n",
    "        ax.set_xlabel('Time (hours)', fontsize=LABEL_FONT)\n",
    "        ax.set_ylabel('OD', fontsize=LABEL_FONT)\n",
    "        ax.set_title(f'{target}', fontsize=TITLE_FONT, pad=15)\n",
    "        ax.set_xlim(time_limit)\n",
    "        \n",
    "        # Axis numbers (Ticks)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=TICK_FONT)\n",
    "\n",
    "        # Legend Styling - Box Restored\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], color='blue', lw=3, label='Mean xylose'),\n",
    "            Patch(facecolor='blue', alpha=0.3, label='SD xylose'),\n",
    "            Line2D([0], [0], color='green', lw=3, label='Mean no xylose'),\n",
    "            Patch(facecolor='green', alpha=0.3, label='SD no xylose')\n",
    "        ]\n",
    "        \n",
    "        # frameon=True (default) keeps the box\n",
    "        ax.legend(handles=legend_elements, loc='upper left', fontsize=LEGEND_FONT, frameon=True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure with target-based filename\n",
    "        safe_name = target.replace(\" \", \"_\")\n",
    "        plt.savefig(f\"{safe_name}_mean_std_xylose.svg\", format=\"svg\", bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "# Run the function\n",
    "plot_gene_targets_mean_std(df_smoothed, ['no_sgRNA', 'rghRA','pgm','sufS','dxr','dapL','coaBC','tagF','dfrA','mnaA','tagB','sunI','hbs', 'mreC', 'rpsB','ligA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_smoothed)\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# NOTE: Replace this section with your actual 'df_smoothed' DataFrame loading\n",
    "# or ensure the following code is applied directly to your existing 'df_smoothed'.\n",
    "\n",
    "# 1. Extract Strain Name and Gene Target using regular expressions\n",
    "# Extract Strain name: captures everything between 'Strain name: ' and the following ';'\n",
    "df_smoothed['Strain_Name'] = df_smoothed['Sample'].str.extract(r'Strain name:\\s*(.*?);')\n",
    "# Extract Gene target: captures everything after 'Gene target: '\n",
    "df_smoothed['Gene_Target'] = df_smoothed['Sample'].str.extract(r'Gene target:\\s*(.*)')\n",
    "\n",
    "# Clean up any potential leading/trailing whitespace\n",
    "df_smoothed['Strain_Name'] = df_smoothed['Strain_Name'].str.strip()\n",
    "df_smoothed['Gene_Target'] = df_smoothed['Gene_Target'].str.strip()\n",
    "\n",
    "# 2. Total number of unique samples (unique Strain Names)\n",
    "unique_strains_count = df_smoothed['Strain_Name'].nunique()\n",
    "\n",
    "# 3. List of all unique sample names (Strain Names)\n",
    "unique_strain_names = df_smoothed['Strain_Name'].unique().tolist()\n",
    "\n",
    "# 4. Count of unique strains that contain 'no_sgRNA' as gene target\n",
    "# First, create a temporary DataFrame with only unique Strain/Target combinations\n",
    "unique_strains_targets = df_smoothed[['Strain_Name', 'Gene_Target']].drop_duplicates()\n",
    "\n",
    "# Then, filter this unique list for 'no_sgRNA' and count the strains\n",
    "no_sgRNA_count = unique_strains_targets[unique_strains_targets['Gene_Target'] == 'no_sgRNA']['Strain_Name'].nunique()\n",
    "\n",
    "print(f\"Total Unique Strains Count: {unique_strains_count}\")\n",
    "print(f\"List of Unique Strain Names: {unique_strain_names}\")\n",
    "print(f\"Unique Strains with 'no_sgRNA' Gene Target Count: {no_sgRNA_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional plotting helpers: specify gene targets and combined xylose/no-xylose plots\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Robust detection of Xylose presence (handles booleans, ints and several strings)\n",
    "def _is_xylose_val(v):\n",
    "    try:\n",
    "        s = str(v).strip().lower()\n",
    "        return s in (\"true\", \"yes\", \"1\", \"xylose\", \"y\")\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# Add a boolean column that flags the presence of xylose if not already present\n",
    "if 'Xylose_flag' not in df_blank_subs.columns:\n",
    "    df_blank_subs['Xylose_flag'] = df_blank_subs['Xylose'].apply(_is_xylose_val)\n",
    "\n",
    "# Regex patterns\n",
    "_no_sg_patterns = re.compile(r'no[_\\-\\s]?s?g?r?n?a?', flags=re.IGNORECASE)\n",
    "_sgl999_pattern = re.compile(r'sgl999', flags=re.IGNORECASE)\n",
    "\n",
    "def is_no_sgRNA(sample):\n",
    "    return bool(_no_sg_patterns.search(str(sample)))\n",
    "\n",
    "\n",
    "def plot_all_with_and_without_xylose(df, time_limit=(0,14), figsize=(12,8)):\n",
    "    \"\"\"\n",
    "    Produces two figures:\n",
    "      - all samples WITH xylose\n",
    "      - all samples WITHOUT xylose\n",
    "\n",
    "    Behavior:\n",
    "      - no_sgRNA samples are combined into ONE group → mean + SD shaded area (red)\n",
    "      - all mutants plotted individually (gray or orange)\n",
    "      - no_sgRNA plotted LAST (higher zorder) so it overlays the others\n",
    "    \"\"\"\n",
    "    d = df.copy()\n",
    "    if 'Xylose_flag' not in d.columns:\n",
    "        d['Xylose_flag'] = d['Xylose'].apply(_is_xylose_val)\n",
    "\n",
    "    groups = {\n",
    "        'xylose': d[d['Xylose_flag'] == True],\n",
    "        'no xylose': d[d['Xylose_flag'] == False]\n",
    "    }\n",
    "\n",
    "    def color_by_substring(sample):\n",
    "        s = str(sample).lower()\n",
    "        if 'sgl999' in s:\n",
    "            return 'orange'\n",
    "        return 'gray'\n",
    "\n",
    "    for title, subdf in groups.items():\n",
    "        if subdf.empty:\n",
    "            print(f'No samples found for group: {title}')\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "\n",
    "        # --- 1) PLOT ALL OTHER SAMPLES FIRST (lower zorder = underneath) ---\n",
    "        other_samples = [s for s in subdf['Sample'].unique() if not is_no_sgRNA(s)]\n",
    "\n",
    "        for sample in other_samples:\n",
    "            sample_data = subdf[subdf['Sample'] == sample]\n",
    "            color = color_by_substring(sample)\n",
    "\n",
    "            stats = sample_data.groupby('Time')['Smoothed_OD'].mean().reset_index()\n",
    "\n",
    "            plt.plot(\n",
    "                stats['Time'], stats['Smoothed_OD'],\n",
    "                color=color, linewidth=1,\n",
    "                zorder=1   # draw below no_sgRNA\n",
    "            )\n",
    "\n",
    "        # --- 2) PLOT no_sgRNA LAST (on top) ---\n",
    "        nosg_df = subdf[subdf['Sample'].apply(is_no_sgRNA)]\n",
    "        if not nosg_df.empty:\n",
    "            nosg_stats = nosg_df.groupby('Time')['Smoothed_OD'].agg(['mean', 'std']).reset_index()\n",
    "            time = nosg_stats['Time']\n",
    "            mean = nosg_stats['mean']\n",
    "            std = nosg_stats['std'].fillna(0)\n",
    "\n",
    "            # SD shaded area (under the line but still above mutants)\n",
    "            plt.fill_between(\n",
    "                time, mean - std, mean + std,\n",
    "                color='red',\n",
    "                alpha=0.2,\n",
    "                edgecolor='none',\n",
    "                zorder=3   # above mutants but under the no_sgRNA line\n",
    "            )\n",
    "\n",
    "            # Solid mean line (drawn on top)\n",
    "            plt.plot(\n",
    "                time, mean,\n",
    "                color='red', linewidth=2,\n",
    "                zorder=4   # very top\n",
    "            )\n",
    "\n",
    "        # Legend\n",
    "        from matplotlib.lines import Line2D\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], color='red', lw=2, label='no_sgRNA (mean ± SD)'),\n",
    "            Line2D([0], [0], color='gray', lw=1, label='mutants'),\n",
    "           \n",
    "        ]\n",
    "\n",
    "        plt.xlabel('Time (hours)')\n",
    "        plt.ylabel('OD')\n",
    "        plt.title(f'{title}')\n",
    "        plt.xlim(time_limit)\n",
    "        plt.ylim((0,1.35))\n",
    "        plt.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "        plt.savefig(f\"{title.replace(' ', '_')}.svg\", format=\"svg\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "plot_all_with_and_without_xylose(df_smoothed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "===========================================================\n",
    "Regression and calculation of growth metrics\n",
    "===========================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Log2 calculation per replicate ---\n",
    "\n",
    "df_log2 = (\n",
    "    df_blank_subs.groupby(['Sample', 'rep','Xylose'])\n",
    "    .apply(calculate_log2)\n",
    "    .drop(columns=['OD', 'Smoothed_OD', 'Blank_value'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(df_log2.head())\n",
    "\n",
    "# --- Extract metrics per replicate ---\n",
    "\n",
    "df_metrics = df_blank_subs.groupby(['Sample', 'rep', 'Xylose']).apply(extract_metrics).reset_index()\n",
    "print(df_metrics.head())\n",
    "\n",
    "# --- Check-up plot for Log2 calculation ---\n",
    "\n",
    "if sample_to_plot in df_log2['Sample'].unique():\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    for (rep,xylose), rep_data in df_log2[df_log2['Sample'] == sample_to_plot].groupby(['rep', 'Xylose']):\n",
    "        ax.plot(rep_data['Time'], rep_data['Log2'], marker='o', linestyle='-', label=f'Rep {rep}{xylose}')\n",
    "    ax.set_xlabel('Time (minutes)')\n",
    "    ax.set_ylabel('Log2(OD)')\n",
    "    ax.set_title(f'Log2(OD) for {sample_to_plot}')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('The specified sample is not present in the Log2-calculated data.')\n",
    "\n",
    "\n",
    "# --- Drop invalid Log2 values ---\n",
    "\n",
    "original_rows = len(df_log2)\n",
    "df_log2 = df_log2.dropna(subset=['Log2'])\n",
    "df_log2 = df_log2[df_log2['Log2'] != -np.inf]\n",
    "new_rows = len(df_log2)\n",
    "\n",
    "print(f\"Number of rows dropped due to NaN or -inf in Log2 column: {original_rows - new_rows}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_df = (\n",
    "    df_log2\n",
    "    .groupby(['Sample','rep','Xylose'])\n",
    "    .apply(lambda g: calculate_sliding_regressions(g, window_regression)\n",
    "           .assign(\n",
    "               Sample=g['Sample'].iloc[0],\n",
    "               rep=g['rep'].iloc[0], Xylose=g['Xylose'].iloc[0],\n",
    "           ))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(regression_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filtering values to select the best candidate for visible exponential phase\n",
    "\n",
    "crit1_linearity = 0.99 # Used in step B of the filtering to discard regressions with a good linear fit (exponential phase should have a bad linear fit). Typically = 0.99\n",
    "crit2_ODincr =  0.002 # Used in step C of first exponential phase filtering to discard regressions with low OD increase. Typically = 0.002\n",
    "crit3_fit =  0.97 # Used in step D of first exponential phase filtering to discard regressions with bad fit (R-squared >= crit3_fit, typically = 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of blank-subtracted OD and rename column to 'Log2' for regression reuse\n",
    "df_od_for_regression = df_blank_subs.copy().rename(columns={'Smoothed_OD_Blank_Sub': 'Log2'})\n",
    "\n",
    "# Run calculate_sliding_regressions on the OD values per sample–replicate, keeping 'xylose'\n",
    "regression_OD_df = (\n",
    "    df_od_for_regression\n",
    "    .groupby(['Sample','rep','Xylose'])\n",
    "    .apply(lambda g: calculate_sliding_regressions(g, window_regression)\n",
    "           .assign(\n",
    "               Sample=g['Sample'].iloc[0],\n",
    "               rep=g['rep'].iloc[0], Xylose=g['Xylose'].iloc[0]\n",
    "           ))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(regression_OD_df)\n",
    "\n",
    "# Merge on Sample, rep, Start_Time, End_Time\n",
    "merged = regression_df.merge(\n",
    "    regression_OD_df[['Sample', 'rep', 'Xylose','Start_Time', 'End_Time', 'R_squared']],\n",
    "    on=['Sample', 'rep','Xylose', 'Start_Time', 'End_Time'],\n",
    "    suffixes=('', '_OD')\n",
    ")\n",
    "\n",
    "# Filter out candidates where the OD linear fit is better than the exponential fit\n",
    "filtered_regression_df = merged[merged['R_squared_OD'] < merged['R_squared']]\n",
    "\n",
    "# Further filter by user-defined linearity threshold\n",
    "filtered_regression_df = filtered_regression_df[filtered_regression_df['R_squared_OD'] < crit1_linearity]\n",
    "\n",
    "# Drop the extra column if desired\n",
    "filtered_regression_df = filtered_regression_df.drop(columns=['R_squared_OD'])\n",
    "\n",
    "# --- Summary prints & plots per replicate ---\n",
    "print('Number of candidate exponential phases before check for exponential fit:')\n",
    "print(regression_df.groupby(['Sample', 'rep', 'Xylose']).size())\n",
    "\n",
    "plot_sample_regressions(df_log2, regression_df, sample_to_plot, \"Candidates before linear check for\")\n",
    "\n",
    "print('Number of candidate exponential phases after check for exponential fit:')\n",
    "print(filtered_regression_df.groupby(['Sample', 'rep', 'Xylose']).size())\n",
    "\n",
    "plot_sample_regressions(df_log2, filtered_regression_df, sample_to_plot, \"Candidates after linear check for\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering of the candidate regressions to extract the exponential phase\n",
    "# Uncomment and change the sample name to plot a different sample\n",
    "# sample_to_plot = 'Sample X6'\n",
    "\n",
    "sorted_df = filtered_regression_df.copy()\n",
    "\n",
    "# Step C: Filter out candidate regressions with low OD differences\n",
    "sorted_df['Start_OD'] = np.power(2, sorted_df['Start_Log2'])\n",
    "sorted_df['End_OD'] = np.power(2, sorted_df['End_Log2'])\n",
    "sorted_df['difference_OD'] = sorted_df['End_OD'] - sorted_df['Start_OD']\n",
    "\n",
    "# Filter per replicate\n",
    "sorted_df = sorted_df[sorted_df['difference_OD'] >= crit2_ODincr].drop('difference_OD', axis=1)\n",
    "\n",
    "# Plot after first filtering step\n",
    "plot_sample_regressions(df_log2, sorted_df, sample_to_plot, 'After removing low OD differences for')\n",
    "\n",
    "# Step D: Keep candidate regressions with high fit scores\n",
    "sorted_df = sorted_df[sorted_df['R_squared'] >= crit3_fit]\n",
    "\n",
    "# Plot after second filtering step\n",
    "plot_sample_regressions(df_log2, sorted_df, sample_to_plot, 'After keeping R-squared >= ' + str(crit3_fit) + ' for')\n",
    "\n",
    "# Save candidates for downstream secondary exponential phase detection\n",
    "sorted_df_secondary_expo = sorted_df.copy()\n",
    "\n",
    "# Step E: Extract candidate regression with the highest slope per replicate\n",
    "sorted_df = sorted_df.sort_values(by='Slope', ascending=False).reset_index(drop=True)\n",
    "sorted_df['Rank_S'] = sorted_df.groupby(['Sample','rep', 'Xylose']).cumcount() + 1\n",
    "\n",
    "# Select the top regression for each sample-replicate\n",
    "top_rows_df = sorted_df[sorted_df['Rank_S'] == 1].drop('Rank_S', axis=1)\n",
    "\n",
    "# Plot the final selection\n",
    "plot_sample_regressions(df_log2, top_rows_df, sample_to_plot, 'Final selection for')\n",
    "\n",
    "# Print the final result\n",
    "print(top_rows_df)\n",
    "\n",
    "# Check the values extracted for one of the samples\n",
    "if sample_to_plot in df_smoothed['Sample'].unique():\n",
    "    print(top_rows_df[(top_rows_df['Sample'] == sample_to_plot)])\n",
    "else:\n",
    "    print('The indicated sample to plot is not present in this acquisition.')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refinement of the exponential phases\n",
    "authorized_diff = 2  # Threshold for refinement (e.g., 1.1–3)\n",
    "print(top_rows_df)\n",
    "# Apply refinement per replicate\n",
    "final_first_expo_df = (\n",
    "    top_rows_df\n",
    "    .groupby(['Sample', 'rep','Xylose'])\n",
    "    .apply(lambda g: refine_exponential_phase(g, df_log2, authorized_diff))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print('dit is final expo df')\n",
    "print(final_first_expo_df)\n",
    "\n",
    "# Plot the best regression for a specific sample\n",
    "# Uncomment and change the sample name to plot a different sample\n",
    "# sample_to_plot = 'Sample X20'\n",
    "\n",
    "# Plot the regressions for the specified sample after refinement\n",
    "plot_sample_regressions(df_log2, final_first_expo_df, sample_to_plot, 'After refinement - Exponential phase of ')\n",
    "\n",
    "# Display the refined data for the selected sample if it exists in the final dataset\n",
    "if sample_to_plot in final_first_expo_df['Sample'].unique():\n",
    "    print(final_first_expo_df[final_first_expo_df['Sample'] == sample_to_plot])\n",
    "else:\n",
    "    print(f\"The sample '{sample_to_plot}' is not present in the final dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Unique strains\n",
    "samples = df_blank_subs['Sample'].unique()\n",
    "nrows = len(samples)\n",
    "ncols = 2  # no xylose vs xylose\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 6 * nrows), squeeze=False)\n",
    "\n",
    "for i, sample in enumerate(samples):\n",
    "    # Subset data for this strain\n",
    "    sample_data = df_blank_subs[df_blank_subs['Sample'] == sample]\n",
    "    sample_expo = final_first_expo_df[final_first_expo_df['Sample'] == sample]\n",
    "\n",
    "    # --- Plot no xylose ---\n",
    "    sample_no_xylose = sample_data[sample_data['Xylose'] == 'no xylose']\n",
    "    for rep, rep_data in sample_no_xylose.groupby('rep'):\n",
    "        axs[i, 0].plot(rep_data['Time'], rep_data['Smoothed_OD_Blank_Sub'], \n",
    "                       label=f'Rep {rep}', alpha=0.7)\n",
    "    \n",
    "    # Highlight exponential phases\n",
    "    for _, row in sample_expo[sample_expo['Xylose'] == 'no xylose'].iterrows():\n",
    "        axs[i, 0].axvspan(row['Start_Time'], row['End_Time'], alpha=0.3, color='green')\n",
    "\n",
    "    axs[i, 0].set_title(f'{sample} - No xylose')\n",
    "    axs[i, 0].set_ylabel('Smoothed OD (Blank Subtracted)')\n",
    "    axs[i, 0].legend(loc='upper left')\n",
    "\n",
    "    # --- Plot with xylose ---\n",
    "    sample_xylose = sample_data[sample_data['Xylose'] != 'no xylose']\n",
    "    for rep, rep_data in sample_xylose.groupby('rep'):\n",
    "        axs[i, 1].plot(rep_data['Time'], rep_data['Smoothed_OD_Blank_Sub'], \n",
    "                       label=f'Rep {rep}', alpha=0.7)\n",
    "    \n",
    "    for _, row in sample_expo[sample_expo['Xylose'] != 'no xylose'].iterrows():\n",
    "        axs[i, 1].axvspan(row['Start_Time'], row['End_Time'], alpha=0.3, color='green')\n",
    "\n",
    "    axs[i, 1].set_title(f'{sample} - With xylose')\n",
    "    axs[i, 1].set_ylabel('Smoothed OD (Blank Subtracted)')\n",
    "    axs[i, 1].legend(loc='upper left')\n",
    "\n",
    "# Set common x-labels\n",
    "for ax in axs[-1, :]:\n",
    "    ax.set_xlabel('Time (minutes)')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.6, wspace=0.3)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add secondary exponential phase data to the final_first_expo_df dataframe\n",
    "# If no secondary phase is available yet, just use first phase\n",
    "growth_data_df = final_first_expo_df.copy()\n",
    "growth_data_df = growth_data_df.drop(columns=['Start_Log2', 'End_Log2'], errors='ignore')\n",
    "print(growth_data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===========================================================\n",
    "Visualization of growth characteristics (quantification)\n",
    "===========================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Calculate and add growth rates & generation times of the first exponential phase ---\n",
    "print(growth_data_df.head())\n",
    "print(df_metrics)\n",
    "\n",
    "# Growth rate per hour and generation time (min)\n",
    "growth_data_df['Growth_rate (.h-1)'] = growth_data_df['Slope'] * 60  \n",
    "growth_data_df['Generation_time (min)'] = 1 / growth_data_df['Slope']\n",
    "\n",
    "# --- Optional: handle 2nd exponential phase if present ---\n",
    "# if 'Slope_2nd' in growth_data_df.columns:\n",
    "#     growth_data_df['Growth_rate (.h-1)_2nd'] = growth_data_df['Slope_2nd'] * 60\n",
    "#     growth_data_df['Generation_time (min)_2nd'] = 1 / growth_data_df['Slope_2nd']\n",
    "\n",
    "# --- Merge growth_data_df with df_metrics ---\n",
    "# Ensure both have 'Xylose' if available\n",
    "\n",
    "# Merge growth_data_df with df_metrics on Sample, rep, and Xylose\n",
    "\n",
    "\n",
    "merge_keys = ['Sample', 'rep', 'Xylose']\n",
    "\n",
    "# Merge all metrics from df_metrics, now including peak summaries\n",
    "growth_data_df = growth_data_df.merge(\n",
    "    df_metrics[[\n",
    "        'Sample', 'rep', 'Xylose',\n",
    "        # AUC metrics\n",
    "        'AUC', 'AUC1', 'AUC2',\n",
    "        # OD metrics\n",
    "        'Max_OD', 'Max_OD_Time (h)', 'Final_OD',\n",
    "        'Max_Slope', 'Decline_Rate', 'Var_dODdt','Num_Peaks',\n",
    "        # Peak summary metrics\n",
    "        'Peak_Height_Max', 'Peak_Height_Mean',\n",
    "        'Peak_Prominence_Max', 'Peak_Prominence_Mean',\n",
    "        'Peak_Left_Base_Max', 'Peak_Left_Base_Mean',\n",
    "        'Peak_Right_Base_Max', 'Peak_Right_Base_Mean',\n",
    "        'Peak_Width_Max', 'Peak_Width_Mean',\n",
    "        'Peak_Width_Height_Max', 'Peak_Width_Height_Mean',\n",
    "        'Peak_Left_IP_Max', 'Peak_Left_IP_Mean',\n",
    "        'Peak_Right_IP_Max', 'Peak_Right_IP_Mean'\n",
    "    ]],\n",
    "    on=merge_keys,\n",
    "    how='left'  # keeps all rows from growth_data_df even if df_metrics is missing\n",
    ")\n",
    "\n",
    "\n",
    "# --- Reorder columns for clarity ---\n",
    "columns_order = [\n",
    "    'Sample', 'rep', 'Xylose',\n",
    "    'Growth_rate (.h-1)', 'Generation_time (min)',\n",
    "    'Start_OD', 'Start_Time', 'End_OD', 'End_Time',\n",
    "    'Slope', 'Intercept', 'R_squared', 'Avg_Residuals',\n",
    "    'AUC', 'AUC1', 'AUC2',\n",
    "    'Max_OD', 'Max_OD_Time (h)', 'Final_OD',\n",
    "    'Max_Slope', 'Decline_Rate', 'Num_Peaks', 'Var_dODdt', \n",
    "    # Peak summaries\n",
    "    'Peak_Height_Max', 'Peak_Height_Mean',\n",
    "    'Peak_Prominence_Max', 'Peak_Prominence_Mean',\n",
    "    'Peak_Left_Base_Max', 'Peak_Left_Base_Mean',\n",
    "    'Peak_Right_Base_Max', 'Peak_Right_Base_Mean',\n",
    "    'Peak_Width_Max', 'Peak_Width_Mean',\n",
    "    'Peak_Width_Height_Max', 'Peak_Width_Height_Mean',\n",
    "    'Peak_Left_IP_Max', 'Peak_Left_IP_Mean',\n",
    "    'Peak_Right_IP_Max', 'Peak_Right_IP_Mean'\n",
    "]\n",
    "\n",
    "# Reorder dataframe\n",
    "growth_data_df = growth_data_df[columns_order]\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "growth_data_df = growth_data_df[columns_order]\n",
    "\n",
    "#\n",
    "\n",
    "# --- Display final per-replicate, per-condition growth data ---\n",
    "print(\"✅ Final growth data (per replicate and xylose condition):\")\n",
    "print(growth_data_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure correct dtype for grouping\n",
    "growth_data_df[\"Xylose\"] = growth_data_df[\"Xylose\"].str.strip().str.lower()\n",
    "\n",
    "# Select numeric columns automatically\n",
    "numeric_cols = growth_data_df.select_dtypes(include=\"number\").columns\n",
    "\n",
    "# Group by Sample and Xylose to compute mean and std\n",
    "grouped = growth_data_df.groupby([\"Sample\", \"Xylose\"], as_index=False)\n",
    "\n",
    "mean_df = grouped[numeric_cols].mean()\n",
    "std_df = grouped[numeric_cols].std()\n",
    "\n",
    "# Add identifiers for rep\n",
    "mean_df[\"rep\"] = \"mean\"\n",
    "std_df[\"rep\"] = \"sd\"\n",
    "\n",
    "# Merge back the non-numeric columns\n",
    "# Keep Sample and Xylose as in the group, fill other columns with NaN\n",
    "mean_df = mean_df.reindex(columns=growth_data_df.columns)\n",
    "std_df = std_df.reindex(columns=growth_data_df.columns)\n",
    "\n",
    "# Combine all: original + mean + sd\n",
    "growth_data_with_avgs = pd.concat([growth_data_df, mean_df, std_df], ignore_index=True)\n",
    "\n",
    "# Sort for neatness\n",
    "growth_data_with_avgs = growth_data_with_avgs.sort_values([\"Sample\", \"Xylose\", \"rep\"]).reset_index(drop=True)\n",
    "\n",
    "print(growth_data_with_avgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Extract Gene target from the Sample column ---\n",
    "def extract_gene_target(sample_str):\n",
    "    match = re.search(r\"Gene target:\\s*([\\w\\-]+)\", str(sample_str))\n",
    "    return match.group(1) if match else sample_str\n",
    "\n",
    "growth_data_with_avgs[\"Gene_target\"] = growth_data_with_avgs[\"Sample\"].apply(extract_gene_target)\n",
    "print(growth_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file into a DataFrame\n",
    "file_path_meta = 'C:/Users/arnou/Documents/thesis/Resultaten/MetaData/growth_category2.xlsx'\n",
    "growth_category = pd.read_excel(file_path_meta)\n",
    "\n",
    "# Merge the two DataFrames on the 'gene target X' column\n",
    "merged_df3 = pd.merge(\n",
    "    growth_data_with_avgs,\n",
    "    growth_category,\n",
    "    on='Gene_target',\n",
    "    how='left'  # keep all rows from growth_data_with_avg\n",
    ")\n",
    "print(merged_df3)\n",
    "# Fill missing growth profile entries with 'Not present'\n",
    "merged_df3['Growth_category'] = merged_df3['Growth_category'].fillna('Not present')\n",
    "growth_data_with_avgs = merged_df3\n",
    "# Optional: inspect the result\n",
    "print(growth_data_with_avgs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# --- Ensure xylose column is consistent ---\n",
    "growth_data_with_avgs[\"Xylose\"] = growth_data_with_avgs[\"Xylose\"].str.strip().str.lower()\n",
    "\n",
    "# --- Select only the mean and sd rows ---\n",
    "mean_df = growth_data_with_avgs[growth_data_with_avgs[\"rep\"] == \"mean\"].copy()\n",
    "sd_df = growth_data_with_avgs[growth_data_with_avgs[\"rep\"] == \"sd\"].copy()\n",
    "\n",
    "\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    print(mean_df)\n",
    "\n",
    "# --- Compute ratio of AUC2/AUC1 (mean and sd) ---\n",
    "mean_df[\"AUC1/AUC2\"] = mean_df[\"AUC1\"] / mean_df[\"AUC2\"]\n",
    "\n",
    "sd_df[\"AUC1/AUC2\"] = mean_df[\"AUC1/AUC2\"] * np.sqrt(\n",
    "    (sd_df[\"AUC1\"] / mean_df[\"AUC1\"])**2 +\n",
    "    (sd_df[\"AUC2\"] / mean_df[\"AUC2\"])**2\n",
    ")\n",
    "\n",
    "\n",
    "mean_df[\"log(AUC1/AUC2)\"] = np.log(mean_df[\"AUC1/AUC2\"])\n",
    "\n",
    "sd_df[\"log(AUC1/AUC2)\"] = np.sqrt(\n",
    "    (sd_df[\"AUC1\"] / mean_df[\"AUC1\"])**2 +\n",
    "    (sd_df[\"AUC2\"] / mean_df[\"AUC2\"])**2\n",
    ")\n",
    "\n",
    "\n",
    "# --- Metrics to plot ---\n",
    "metrics_to_plot = [\n",
    "    \"AUC\", \"AUC1\", \"AUC2\", \"AUC1/AUC2\", \"log(AUC1/AUC2)\",\n",
    "    \"Max_OD\", \"Max_OD_Time (h)\", \"Final_OD\",\n",
    "    \"Max_Slope\", \"Decline_Rate\", \"Num_Peaks\", \"Var_dODdt\",  'Max_Slope', 'Decline_Rate', 'Num_Peaks',\n",
    "    \"Peak_Height_Max\", \"Peak_Height_Mean\",\n",
    "    \"Peak_Prominence_Max\", \"Peak_Prominence_Mean\",\n",
    "    \"Peak_Left_Base_Max\", \"Peak_Left_Base_Mean\",\n",
    "    \"Peak_Right_Base_Max\", \"Peak_Right_Base_Mean\",\n",
    "    \"Peak_Width_Max\", \"Peak_Width_Mean\",\n",
    "    \"Peak_Width_Height_Max\", \"Peak_Width_Height_Mean\",\n",
    "    \"Peak_Left_IP_Max\", \"Peak_Left_IP_Mean\",\n",
    "    \"Peak_Right_IP_Max\", \"Peak_Right_IP_Mean\"\n",
    "]\n",
    "print(mean_df)\n",
    "def split_dataframe_evenly(df, n_parts=2):\n",
    "    \"\"\"Split dataframe into nearly equal chunks by number of rows.\"\"\"\n",
    "    df_sorted = df.sort_values(\"Gene_target\").reset_index(drop=True)\n",
    "    n = len(df_sorted)\n",
    "    size = math.ceil(n / n_parts)\n",
    "    return [df_sorted.iloc[i:i + size] for i in range(0, n, size)]\n",
    "\n",
    "def plot_metric_in_chunks(df_subset, condition_label, metric_name, n_chunks=2):\n",
    "    \"\"\"Plot metric with equal-sized x-axis chunks and color by growth profile.\"\"\"\n",
    "    chunks = split_dataframe_evenly(df_subset, n_chunks)\n",
    "    n_chunks = len(chunks)\n",
    "    fig, axes = plt.subplots(n_chunks, 1, figsize=(14, 6 * n_chunks), sharey=True)\n",
    "\n",
    "    if n_chunks == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Assign a distinct color for each growth profile\n",
    "    profiles = df_subset[\"Growth_category_mean\"].unique()\n",
    "    colors = plt.cm.tab10.colors  # up to 10 colors\n",
    "    profile_color_map = {profile: colors[i % len(colors)] for i, profile in enumerate(profiles)}\n",
    "\n",
    "    for i, (ax, chunk) in enumerate(zip(axes, chunks)):\n",
    "        for profile in profiles:\n",
    "            profile_chunk = chunk[chunk[\"Growth_category_mean\"] == profile]\n",
    "            if profile_chunk.empty:\n",
    "                continue\n",
    "            ax.errorbar(\n",
    "                x=profile_chunk[\"Gene_target\"],\n",
    "                y=profile_chunk[f\"{metric_name}_mean\"],\n",
    "                yerr=profile_chunk[f\"{metric_name}_sd\"],\n",
    "                fmt='o',\n",
    "                ecolor='gray',\n",
    "                capsize=5,\n",
    "                markersize=6,\n",
    "                linestyle='None',\n",
    "                color=profile_color_map[profile],\n",
    "                label=profile\n",
    "            )\n",
    "        ax.set_title(f\"{metric_name} ({condition_label}) – Part {i+1}\", fontsize=11)\n",
    "        ax.set_xlabel(\"Gene_target\", fontsize=9)\n",
    "        ax.set_ylabel(metric_name, fontsize=9)\n",
    "        ax.tick_params(axis='x', rotation=90, labelsize=8)\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "        ax.legend(title=\"Growth profile\", fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Main plotting loop ---\n",
    "for metric in metrics_to_plot:\n",
    "    merged_stats = pd.merge(\n",
    "        mean_df[[\"Sample\", \"Gene_target\", \"Xylose\", \"Growth_category\", metric]],\n",
    "        sd_df[[\"Sample\", \"Gene_target\", \"Xylose\", \"Growth_category\", metric]],\n",
    "        on=[\"Sample\", \"Gene_target\", \"Xylose\"],\n",
    "        suffixes=(\"_mean\", \"_sd\")\n",
    "    )\n",
    "    print(merged_stats)\n",
    "    merged_xylose = merged_stats[merged_stats[\"Xylose\"] == \"xylose\"]\n",
    "    merged_no_xylose = merged_stats[merged_stats[\"Xylose\"] == \"no xylose\"]\n",
    "\n",
    "    plot_metric_in_chunks(merged_xylose, \"with xylose\", metric)\n",
    "    plot_metric_in_chunks(merged_no_xylose, \"without xylose\", metric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ensure xylose column is consistent ---\n",
    "growth_data_with_avgs[\"Xylose\"] = growth_data_with_avgs[\"Xylose\"].str.strip().str.lower()\n",
    "\n",
    "# --- Select only the mean and sd rows ---\n",
    "mean_df = growth_data_with_avgs[growth_data_with_avgs[\"rep\"] == \"mean\"]\n",
    "sd_df = growth_data_with_avgs[growth_data_with_avgs[\"rep\"] == \"sd\"]\n",
    "\n",
    "# --- Merge means and SDs ---\n",
    "merged_stats = pd.merge(\n",
    "    mean_df[[\"Sample\", \"Xylose\", \"AUC\"]],\n",
    "    sd_df[[\"Sample\", \"Xylose\", \"AUC\"]],\n",
    "    on=[\"Sample\", \"Xylose\"],\n",
    "    suffixes=(\"_mean\", \"_sd\")\n",
    ")\n",
    "\n",
    "# --- Separate xylose and no xylose ---\n",
    "df_xylose = merged_stats[merged_stats[\"Xylose\"] == \"xylose\"].set_index(\"Sample\")\n",
    "df_noxylose = merged_stats[merged_stats[\"Xylose\"] == \"no xylose\"].set_index(\"Sample\")\n",
    "\n",
    "# --- Keep only samples that exist in both conditions ---\n",
    "common_samples = df_xylose.index.intersection(df_noxylose.index)\n",
    "df_xylose = df_xylose.loc[common_samples]\n",
    "df_noxylose = df_noxylose.loc[common_samples]\n",
    "\n",
    "# --- Compute ratio and propagated SD ---\n",
    "ratio_mean = df_xylose[\"AUC_mean\"] / df_noxylose[\"AUC_mean\"]\n",
    "\n",
    "# Error propagation for ratio (R = A/B):\n",
    "# (σ_R / R)^2 = (σ_A / A)^2 + (σ_B / B)^2\n",
    "ratio_sd = ratio_mean * np.sqrt(\n",
    "    (df_xylose[\"AUC_sd\"] / df_xylose[\"AUC_mean\"])**2 +\n",
    "    (df_noxylose[\"AUC_sd\"] / df_noxylose[\"AUC_mean\"])**2\n",
    ")\n",
    "\n",
    "# --- Combine into single dataframe ---\n",
    "auc_ratio_df = pd.DataFrame({\n",
    "    \"Sample\": common_samples,\n",
    "    \"AUC_ratio_mean\": ratio_mean,\n",
    "    \"AUC_ratio_sd\": ratio_sd\n",
    "}).reset_index(drop=True)\n",
    "# Add back Gene_target metadata\n",
    "print(auc_ratio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# --- extract gene target (leave values as-is, don't rename) ---\n",
    "def extract_gene_target(sample_str):\n",
    "    match = re.search(r\"Gene target:\\s*([\\w\\-]+)\", str(sample_str))\n",
    "    return match.group(1) if match else sample_str\n",
    "\n",
    "auc_ratio_df[\"Gene_target\"] = auc_ratio_df[\"Sample\"].apply(extract_gene_target)\n",
    "\n",
    "# --- prepare sorted DataFrame: controls (no_sgRNA) leftmost, others sorted desc ---\n",
    "mask_no = auc_ratio_df[\"Gene_target\"].str.lower() == \"no_sgRNA\".lower()\n",
    "\n",
    "df_controls = auc_ratio_df[mask_no].copy().reset_index(drop=True)        # keep original order\n",
    "df_others   = auc_ratio_df[~mask_no].sort_values(\"AUC_ratio_mean\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "auc_sorted = pd.concat([df_controls, df_others], ignore_index=True)\n",
    "\n",
    "# --- plotting: red for controls, black for others; x-axis labels = Gene_target (no renaming) ---\n",
    "colors = [\"red\" if gt.lower() == \"no_sgrna\" else \"black\" for gt in auc_sorted[\"Gene_target\"]]\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "\n",
    "# errorbars (gray)\n",
    "plt.errorbar(\n",
    "    x=range(len(auc_sorted)),                            # use numeric x for proper spacing when labels duplicate\n",
    "    y=auc_sorted[\"AUC_ratio_mean\"],\n",
    "    yerr=auc_sorted[\"AUC_ratio_sd\"],\n",
    "    fmt='none',                                         # draw only errorbars here\n",
    "    ecolor='gray',\n",
    "    capsize=5,\n",
    "    zorder=1\n",
    ")\n",
    "\n",
    "# points colored\n",
    "plt.scatter(\n",
    "    x=range(len(auc_sorted)),\n",
    "    y=auc_sorted[\"AUC_ratio_mean\"],\n",
    "    c=colors,\n",
    "    s=30,\n",
    "    zorder=3\n",
    ")\n",
    "\n",
    "plt.axhline(1, color='black', linestyle='--', alpha=0.7, label='Ratio = 1 (equal AUC)')\n",
    "\n",
    "# set x-ticks to gene target labels (duplicates allowed)\n",
    "plt.xticks(ticks=range(len(auc_sorted)), labels=auc_sorted[\"Gene_target\"], rotation=60, ha='right')\n",
    "\n",
    "plt.title(\"AUC Ratio (xylose / no xylose) ± SD\", fontsize=14)\n",
    "plt.xlabel(\"Gene target\", fontsize=12)\n",
    "plt.ylabel(\"AUC Ratio\", fontsize=12)\n",
    "#plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "# optional legend for colors\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=8, label='no_sgRNA'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='black', markersize=8, label='mutants'),\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"AUCratio_eerstnosgrna_danrest.svg\", format=\"svg\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_no = auc_ratio_df[\"Gene_target\"].str.lower() == \"no_sgRNA\".lower()\n",
    "\n",
    "# --- count strains ---\n",
    "total_strains = len(auc_ratio_df)\n",
    "num_no_sgRNA = mask_no.sum()\n",
    "num_with_sgRNA = total_strains - num_no_sgRNA\n",
    "\n",
    "print(f\"Total strains: {total_strains}\")\n",
    "print(f\"no_sgRNA strains: {num_no_sgRNA}\")\n",
    "print(f\"With sgRNA strains: {num_with_sgRNA}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# --- Ensure xylose column is consistent ---\n",
    "growth_data_with_avgs[\"Xylose\"] = growth_data_with_avgs[\"Xylose\"].str.strip().str.lower()\n",
    "\n",
    "# --- Select only mean and sd rows ---\n",
    "mean_df = growth_data_with_avgs[growth_data_with_avgs[\"rep\"] == \"mean\"]\n",
    "sd_df = growth_data_with_avgs[growth_data_with_avgs[\"rep\"] == \"sd\"]\n",
    "\n",
    "# --- Merge means and SDs for AUC ratio calculation ---\n",
    "merged_stats = pd.merge(\n",
    "    mean_df[[\"Sample\", \"Xylose\", \"AUC\", \"Growth_category\"]],\n",
    "    sd_df[[\"Sample\", \"Xylose\", \"AUC\"]],\n",
    "    on=[\"Sample\", \"Xylose\"],\n",
    "    suffixes=(\"_mean\", \"_sd\")\n",
    ")\n",
    "\n",
    "# --- Separate xylose and no xylose ---\n",
    "df_xylose = merged_stats[merged_stats[\"Xylose\"] == \"xylose\"].set_index(\"Sample\")\n",
    "df_noxylose = merged_stats[merged_stats[\"Xylose\"] == \"no xylose\"].set_index(\"Sample\")\n",
    "\n",
    "# --- Keep only samples present in both conditions ---\n",
    "common_samples = df_xylose.index.intersection(df_noxylose.index)\n",
    "df_xylose = df_xylose.loc[common_samples]\n",
    "df_noxylose = df_noxylose.loc[common_samples]\n",
    "\n",
    "# --- Compute AUC ratio and propagated SD ---\n",
    "ratio_mean = df_xylose[\"AUC_mean\"] / df_noxylose[\"AUC_mean\"]\n",
    "ratio_sd = ratio_mean * np.sqrt(\n",
    "    (df_xylose[\"AUC_sd\"] / df_xylose[\"AUC_mean\"])**2 +\n",
    "    (df_noxylose[\"AUC_sd\"] / df_noxylose[\"AUC_mean\"])**2\n",
    ")\n",
    "\n",
    "# --- Combine into AUC ratio dataframe ---\n",
    "auc_ratio_df = pd.DataFrame({\n",
    "    \"Sample\": common_samples,\n",
    "    \"AUC_ratio_mean\": ratio_mean,\n",
    "    \"AUC_ratio_sd\": ratio_sd,\n",
    "    \"Growth_category\": df_xylose[\"Growth_category\"].values\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# --- Extract Gene target from the Sample column ---\n",
    "def extract_gene_target(sample_str):\n",
    "    match = re.search(r\"Gene target:\\s*([\\w\\-]+)\", str(sample_str))\n",
    "    return match.group(1) if match else sample_str\n",
    "\n",
    "auc_ratio_df[\"Gene_target\"] = auc_ratio_df[\"Sample\"].apply(extract_gene_target)\n",
    "\n",
    "# --- Add AUC1/AUC2 log ratio ---\n",
    "mean_df[\"AUC1/AUC2\"] = mean_df[\"AUC1\"] / mean_df[\"AUC2\"]\n",
    "mean_df[\"log(AUC1/AUC2)\"] = np.log(mean_df[\"AUC1/AUC2\"])\n",
    "\n",
    "# --- Merge AUC ratio into mean_df ---\n",
    "mean_df = mean_df.merge(\n",
    "    auc_ratio_df[[\"Sample\", \"AUC_ratio_mean\"]],\n",
    "    on=\"Sample\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# --- Define metrics for PCA (including AUC ratio) ---\n",
    "metrics_for_pca = [\n",
    "    # --- AUC-related ---\n",
    "   \n",
    "   \n",
    "    \"log(AUC1/AUC2)\",\n",
    "    \"AUC_ratio_mean\",\n",
    "    \n",
    "    # --- OD (Optical Density) Metrics ---\n",
    "    \"Max_OD\",\n",
    "    \"Max_OD_Time (h)\",\n",
    "    \"Final_OD\",\n",
    "    \n",
    "    # --- Peak Metrics ---\n",
    "    \"Peak_Prominence_Max\"\n",
    "]\n",
    "\n",
    "# --- Filter mean_df for xylose condition and chosen metrics ---\n",
    "pca_df = mean_df[mean_df[\"Xylose\"] == \"xylose\"].copy()\n",
    "pca_df = pca_df[[\"Sample\", \"Gene_target\", \"Growth_category\"] + metrics_for_pca].set_index(\"Sample\")\n",
    "\n",
    "# --- Replace missing metric values with 0 instead of dropping ---\n",
    "pca_df_clean = pca_df.copy()\n",
    "pca_df_clean[metrics_for_pca] = pca_df_clean[metrics_for_pca].fillna(0)\n",
    "# List strains where Peak_Prominence_Max is 0\n",
    "zero_peak_strains = pca_df_clean[pca_df_clean[\"Peak_Prominence_Max\"] == 0]\n",
    "\n",
    "print(\"Number of strains with Peak_Prominence_Max = 0:\", len(zero_peak_strains))\n",
    "print(zero_peak_strains.index.tolist())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Standardize metrics ---\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(pca_df_clean[metrics_for_pca])\n",
    "\n",
    "# --- Run PCA ---\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# --- Create PCA result dataframe ---\n",
    "pca_result_df = pd.DataFrame(\n",
    "    X_pca,\n",
    "    columns=[\"PC1\", \"PC2\"],\n",
    "    index=pca_df_clean.index\n",
    ")\n",
    "pca_result_df[\"Gene_target\"] = pca_df_clean[\"Gene_target\"]\n",
    "\n",
    "# --- Plot PCA with points in black except for no_sgRNA in red ---\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# --- Parameters for labeling ---\n",
    "min_distance = 0.8   # distance threshold to consider \"close\"\n",
    "max_cluster_size = 5  # clusters larger than this are not labeled\n",
    "text_offset = 0.04    # offset for text from the points\n",
    "\n",
    "positions = pca_result_df[[\"PC1\", \"PC2\"]].to_numpy()\n",
    "labels = pca_result_df[\"Gene_target\"].to_numpy()\n",
    "\n",
    "# Compute pairwise distances\n",
    "dist_matrix = squareform(pdist(positions))\n",
    "\n",
    "# Determine cluster sizes (number of neighbors within min_distance)\n",
    "cluster_sizes = np.sum(dist_matrix < min_distance, axis=1) - 1  # subtract 1 to ignore self\n",
    "\n",
    "# --- Plot PCA ---\n",
    "plt.figure(figsize=(9, 7))\n",
    "\n",
    "# Plot non-control samples (all genes except no_sgRNA) first\n",
    "non_control = pca_result_df[pca_result_df[\"Gene_target\"].str.lower() != \"no_sgrna\"]\n",
    "plt.scatter(\n",
    "    non_control[\"PC1\"],\n",
    "    non_control[\"PC2\"],\n",
    "    color='black',\n",
    "    label='All genes',\n",
    "    s=30,\n",
    "    alpha=0.8,\n",
    "    zorder=1  # background\n",
    ")\n",
    "\n",
    "# Plot control samples (no_sgRNA) last to appear in foreground\n",
    "control = pca_result_df[pca_result_df[\"Gene_target\"].str.lower() == \"no_sgrna\"]\n",
    "if not control.empty:\n",
    "    plt.scatter(\n",
    "        control[\"PC1\"],\n",
    "        control[\"PC2\"],\n",
    "        color='red',\n",
    "        label='no_sgRNA',\n",
    "        s=30,\n",
    "        alpha=0.8,\n",
    "        zorder=2  # foreground\n",
    "    )\n",
    "\n",
    "# --- Add gene target labels with offset ---\n",
    "for i, (x, y) in enumerate(positions):\n",
    "    # Label if small cluster (<= max_cluster_size) or always for no_sgRNA, schrijf no_sgrna in keline letterso meht te laten werken\n",
    "    # --- Add labels only for non-no_sgrna + small clusters ---\n",
    "\n",
    "    if labels[i].lower() == \"no_sgrna\":\n",
    "        continue\n",
    "\n",
    "    if cluster_sizes[i] <= max_cluster_size or labels[i].lower() == \"no_sgRNA\":\n",
    "        plt.text(x + text_offset, y + text_offset, labels[i], fontsize=8, alpha=0.8, zorder=3)\n",
    "\n",
    "plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)\")\n",
    "plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)\")\n",
    "plt.title(\"PCA of Selected Metrics (xylose condition)\")\n",
    "#plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"pcaRed_BlackJuist1zonderauc.svg\", format=\"svg\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Number of strains plotted in PCA: {len(pca_result_df)}\")\n",
    "print(f\"Number of strains plotted in PCA zonder nosgrna: {len(pca_result_df[pca_result_df[\"Gene_target\"].str.lower() != \"no_sgrna\"])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigger font:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# --- GLOBAL FONT SETTINGS (Doubled) ---\n",
    "plt.rcParams.update({\n",
    "    'font.size': 18,          # Base font size\n",
    "    'axes.titlesize': 24,      # Title font size\n",
    "    'axes.labelsize': 20,      # X and Y label font size\n",
    "    'xtick.labelsize': 16,     # X axis tick numbers\n",
    "    'ytick.labelsize': 16,     # Y axis tick numbers\n",
    "    'legend.fontsize': 16,     # Legend font size\n",
    "    'figure.titlesize': 26     # Figure title\n",
    "})\n",
    "\n",
    "# [Existing data processing code remains the same...]\n",
    "# (Keeping the logic until the plotting sections)\n",
    "\n",
    "# --- Parameters for labeling ---\n",
    "min_distance = 0.8\n",
    "max_cluster_size = 5\n",
    "text_offset = 0.04\n",
    "gene_label_size = 16  # Doubled from 8\n",
    "\n",
    "# ==========================\n",
    "#     PCA SCATTER PLOT\n",
    "#  Color = AUC_ratio_mean\n",
    "# ==========================\n",
    "\n",
    "plt.figure(figsize=(12, 9)) # Increased figure size slightly for larger fonts\n",
    "\n",
    "color_values = pca_df_clean.loc[pca_result_df.index, \"AUC_ratio_mean\"]\n",
    "\n",
    "scatter = plt.scatter(\n",
    "    pca_result_df[\"PC1\"],\n",
    "    pca_result_df[\"PC2\"],\n",
    "    c=color_values,\n",
    "    cmap=\"Reds\",\n",
    "    s=60, # Increased dot size slightly to match font\n",
    "    alpha=0.9,\n",
    "    edgecolors=\"black\",\n",
    "    linewidths=0.3\n",
    ")\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label(\"AUC ratio (xylose / no xylose)\", size=20)\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "# --- Add gene target labels ---\n",
    "for i, (x, y) in enumerate(positions):\n",
    "    if labels[i].lower() == \"no_sgrna\":\n",
    "        continue\n",
    "    if cluster_sizes[i] <= max_cluster_size:\n",
    "        # Changed fontsize to gene_label_size variable\n",
    "        plt.text(x + text_offset, y + text_offset, labels[i], fontsize=gene_label_size, alpha=0.8)\n",
    "\n",
    "plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)\")\n",
    "plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)\")\n",
    "plt.title(\"PCA of Selected Metrics (xylose condition)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"pca_AUCratio_colored.svg\", format=\"svg\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ================================\n",
    "#  GENERATE SEPARATE PCA PLOTS\n",
    "# ================================\n",
    "\n",
    "metrics_to_plot = [\n",
    "    \"log(AUC1/AUC2)\",\n",
    "    \"AUC_ratio_mean\",\n",
    "    \"Max_OD\",\n",
    "    \"Max_OD_Time (h)\",\n",
    "    \"Final_OD\",\n",
    "    \"Peak_Prominence_Max\"\n",
    "]\n",
    "\n",
    "for metric in metrics_to_plot:\n",
    "    plt.figure(figsize=(12, 9))\n",
    "\n",
    "    color_values = pca_df_clean.loc[pca_result_df.index, metric]\n",
    "\n",
    "    scatter = plt.scatter(\n",
    "        pca_result_df[\"PC1\"],\n",
    "        pca_result_df[\"PC2\"],\n",
    "        c=color_values,\n",
    "        cmap=\"Reds\",\n",
    "        s=60,\n",
    "        alpha=0.9,\n",
    "        edgecolors=\"black\",\n",
    "        linewidths=0.3\n",
    "    )\n",
    "\n",
    "    cbar = plt.colorbar(scatter)\n",
    "    cbar.set_label(metric, size=20)\n",
    "    cbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "    for i, (x, y) in enumerate(positions):\n",
    "        if cluster_sizes[i] <= max_cluster_size:\n",
    "            plt.text(x + text_offset, y + text_offset, labels[i], fontsize=gene_label_size, alpha=0.8)\n",
    "\n",
    "    plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)\")\n",
    "    plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)\")\n",
    "    plt.title(f\"PCA Colored by {metric}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"PCA_{metric.replace('/', '_').replace(' ', '_')}.svg\", format=\"svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# --- Ensure xylose column is consistent ---\n",
    "growth_data_with_avgs[\"Xylose\"] = growth_data_with_avgs[\"Xylose\"].str.strip().str.lower()\n",
    "\n",
    "# --- Select only mean and sd rows ---\n",
    "mean_df = growth_data_with_avgs[growth_data_with_avgs[\"rep\"] == \"mean\"]\n",
    "sd_df = growth_data_with_avgs[growth_data_with_avgs[\"rep\"] == \"sd\"]\n",
    "\n",
    "# --- Merge means and SDs for AUC ratio calculation ---\n",
    "merged_stats = pd.merge(\n",
    "    mean_df[[\"Sample\", \"Xylose\", \"AUC\", \"Growth_category\"]],\n",
    "    sd_df[[\"Sample\", \"Xylose\", \"AUC\"]],\n",
    "    on=[\"Sample\", \"Xylose\"],\n",
    "    suffixes=(\"_mean\", \"_sd\")\n",
    ")\n",
    "\n",
    "# --- Separate xylose and no xylose ---\n",
    "df_xylose = merged_stats[merged_stats[\"Xylose\"] == \"xylose\"].set_index(\"Sample\")\n",
    "df_noxylose = merged_stats[merged_stats[\"Xylose\"] == \"no xylose\"].set_index(\"Sample\")\n",
    "\n",
    "# --- Keep only samples present in both conditions ---\n",
    "common_samples = df_xylose.index.intersection(df_noxylose.index)\n",
    "df_xylose = df_xylose.loc[common_samples]\n",
    "df_noxylose = df_noxylose.loc[common_samples]\n",
    "\n",
    "# --- Compute AUC ratio and propagated SD ---\n",
    "ratio_mean = df_xylose[\"AUC_mean\"] / df_noxylose[\"AUC_mean\"]\n",
    "ratio_sd = ratio_mean * np.sqrt(\n",
    "    (df_xylose[\"AUC_sd\"] / df_xylose[\"AUC_mean\"])**2 +\n",
    "    (df_noxylose[\"AUC_sd\"] / df_noxylose[\"AUC_mean\"])**2\n",
    ")\n",
    "\n",
    "# --- Combine into AUC ratio dataframe ---\n",
    "auc_ratio_df = pd.DataFrame({\n",
    "    \"Sample\": common_samples,\n",
    "    \"AUC_ratio_mean\": ratio_mean,\n",
    "    \"AUC_ratio_sd\": ratio_sd,\n",
    "    \"Growth_category\": df_xylose[\"Growth_category\"].values\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# --- Extract Gene target from the Sample column ---\n",
    "def extract_gene_target(sample_str):\n",
    "    match = re.search(r\"Gene target:\\s*([\\w\\-]+)\", str(sample_str))\n",
    "    return match.group(1) if match else sample_str\n",
    "\n",
    "auc_ratio_df[\"Gene_target\"] = auc_ratio_df[\"Sample\"].apply(extract_gene_target)\n",
    "\n",
    "# --- Add AUC1/AUC2 log ratio ---\n",
    "mean_df[\"AUC1/AUC2\"] = mean_df[\"AUC1\"] / mean_df[\"AUC2\"]\n",
    "mean_df[\"log(AUC1/AUC2)\"] = np.log(mean_df[\"AUC1/AUC2\"])\n",
    "\n",
    "# --- Merge AUC ratio into mean_df ---\n",
    "mean_df = mean_df.merge(\n",
    "    auc_ratio_df[[\"Sample\", \"AUC_ratio_mean\"]],\n",
    "    on=\"Sample\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# --- Define metrics for PCA (including AUC ratio) ---\n",
    "metrics_for_pca = [\n",
    "    # --- AUC-related ---\n",
    "    \n",
    "   \n",
    "    \"log(AUC1/AUC2)\",\n",
    "    \"AUC_ratio_mean\",\n",
    "    \n",
    "    # --- OD (Optical Density) Metrics ---\n",
    "    \"Max_OD\",\n",
    "    \"Max_OD_Time (h)\",\n",
    "    \"Final_OD\",\n",
    "    \n",
    "    # --- Peak Metrics ---\n",
    "    \"Peak_Prominence_Max\"\n",
    "]\n",
    "\n",
    "# --- Filter mean_df for xylose condition and chosen metrics ---\n",
    "pca_df = mean_df[mean_df[\"Xylose\"] == \"xylose\"].copy()\n",
    "pca_df = pca_df[[\"Sample\", \"Gene_target\", \"Growth_category\"] + metrics_for_pca].set_index(\"Sample\")\n",
    "\n",
    "# --- Drop samples with missing values in PCA metrics ---\n",
    "# --- Replace missing metric values with 0 instead of dropping ---\n",
    "pca_df_clean = pca_df.copy()\n",
    "pca_df_clean[metrics_for_pca] = pca_df_clean[metrics_for_pca].fillna(0)\n",
    "# List strains where Peak_Prominence_Max is 0\n",
    "zero_peak_strains = pca_df_clean[pca_df_clean[\"Peak_Prominence_Max\"] == 0]\n",
    "\n",
    "print(\"Number of strains with Peak_Prominence_Max = 0:\", len(zero_peak_strains))\n",
    "print(zero_peak_strains.index.tolist())\n",
    "\n",
    "# --- Standardize metrics ---\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(pca_df_clean[metrics_for_pca])\n",
    "\n",
    "# --- Run PCA ---\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# --- Create PCA result dataframe ---\n",
    "pca_result_df = pd.DataFrame(\n",
    "    X_pca,\n",
    "    columns=[\"PC1\", \"PC2\"],\n",
    "    index=pca_df_clean.index\n",
    ")\n",
    "pca_result_df[\"Gene_target\"] = pca_df_clean[\"Gene_target\"]\n",
    "\n",
    "# --- Plot PCA with points in black except for no_sgRNA in red ---\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# --- Parameters for labeling ---\n",
    "min_distance = 0.8   # distance threshold to consider \"close\"\n",
    "max_cluster_size = 5  # clusters larger than this are not labeled\n",
    "text_offset = 0.04    # offset for text from the points\n",
    "\n",
    "positions = pca_result_df[[\"PC1\", \"PC2\"]].to_numpy()\n",
    "labels = pca_result_df[\"Gene_target\"].to_numpy()\n",
    "\n",
    "# Compute pairwise distances\n",
    "dist_matrix = squareform(pdist(positions))\n",
    "\n",
    "# Determine cluster sizes (number of neighbors within min_distance)\n",
    "cluster_sizes = np.sum(dist_matrix < min_distance, axis=1) - 1  # subtract 1 to ignore self\n",
    "\n",
    "# --- Plot PCA ---\n",
    "plt.figure(figsize=(9, 7))\n",
    "\n",
    "# Plot non-control samples (all genes except no_sgRNA) first\n",
    "non_control = pca_result_df[pca_result_df[\"Gene_target\"].str.lower() != \"no_sgrna\"]\n",
    "plt.scatter(\n",
    "    non_control[\"PC1\"],\n",
    "    non_control[\"PC2\"],\n",
    "    color='black',\n",
    "    label='All genes',\n",
    "    s=30,\n",
    "    alpha=0.8,\n",
    "    zorder=1  # background\n",
    ")\n",
    "\n",
    "# Plot control samples (no_sgRNA) last to appear in foreground\n",
    "control = pca_result_df[pca_result_df[\"Gene_target\"].str.lower() == \"no_sgrna\"]\n",
    "if not control.empty:\n",
    "    plt.scatter(\n",
    "        control[\"PC1\"],\n",
    "        control[\"PC2\"],\n",
    "        color='red',\n",
    "        \n",
    "        s=30,\n",
    "        alpha=0.8,\n",
    "        zorder=2  # foreground\n",
    "    )\n",
    "# --- Highlight specific gene targets ---\n",
    "highlight_genes = [\"dxr\", \"sufs\", \"pgm\", \"pheS\",\"ylan27_1\",\"ylan27_2\",\"acps50_1\",\"acps50_2\", \"ftsz226\",\"ftsz\",\"mreC\"]  # <--- write small letters\n",
    "\n",
    "highlight_df = pca_result_df[pca_result_df[\"Gene_target\"].str.lower().isin(highlight_genes)]\n",
    "\n",
    "# Plot highlighted points in cyan\n",
    "plt.scatter(\n",
    "    highlight_df[\"PC1\"],\n",
    "    highlight_df[\"PC2\"],\n",
    "    color='cyan',\n",
    "    s=30,\n",
    "    edgecolor='black',\n",
    "    linewidth=0.8,\n",
    "    zorder=5,\n",
    "    label=\"Highlighted genes\"\n",
    ")\n",
    "\n",
    "# Force labeling of highlighted genes\n",
    "force_label_indices = highlight_df.index.tolist()\n",
    "for i, (x, y) in enumerate(positions):\n",
    "    gt = labels[i].lower()\n",
    "\n",
    "    if (i in force_label_indices) or (cluster_sizes[i] <= max_cluster_size) or (gt == \"no_sgrna\"):\n",
    "        plt.text(x + text_offset, y + text_offset, labels[i], fontsize=8, alpha=0.9, zorder=6)\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)\")\n",
    "plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)\")\n",
    "plt.title(\"PCA of Selected Metrics (xylose condition)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"pcaRed_BlackJuist1.svg\", format=\"svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
